<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CART</title>
    <url>/2019/10/15/CART/</url>
    <content><![CDATA[<p>这里说的树都是二叉树。</p>
<p>结点<span class="math inline">\(t\)</span>代表输入空间中的一块区域。<span class="math inline">\(p(t)\)</span>为随机采样一个数据点，这个点在<span class="math inline">\(t\)</span>中的概率。</p>
<p>对于<span class="math inline">\(K\)</span>个类的概率（满足<span class="math inline">\(p_i\ge0,\sum_{i=1}^K p_i=1\)</span>），定义impurity函数<span class="math inline">\(\phi(p_1,\cdots,p_K)\)</span>，如entropy，Gini index。</p>
<p>定义结点<span class="math inline">\(t\)</span>的impurity（measure）<span class="math inline">\(i(t)=\phi(p(1|t),\cdots,p(K|T))\)</span></p>
<p>划分<span class="math inline">\(\mathfrak{s}\)</span>将<span class="math inline">\(t\)</span>分为<span class="math inline">\(t_L,t_R\)</span>两个子节点，定义<span class="math inline">\(p_L=p(t_L)/p(t)\)</span>，类似定义<span class="math inline">\(p_R\)</span>，显然<span class="math inline">\(p_L+p_R=1\)</span>。定义impurity的减少为： <span class="math display">\[
\Delta i(\mathfrak{s},t)=i(t)-p_Li(t_L)-p_Ri(t_R)
\]</span> 结点<span class="math inline">\(t\)</span>的impurity：<span class="math inline">\(I(t)=i(t)p(t)\)</span></p>
<p><span class="math inline">\(T\)</span>表示一棵树，<span class="math inline">\(\tilde{T}\)</span>表示叶结点集合，<span class="math inline">\(T\)</span>的impurity： <span class="math display">\[
I(T)=\sum_{t\in\tilde{T}}I(t)
\]</span> 定义 <span class="math display">\[
\Delta I(\mathfrak{s},t)=I(t)-T(t_L)-I(t_R)
\]</span> 可得： <span class="math display">\[
\Delta I(\mathfrak{s},t)=\Delta i(\mathfrak{s},t)p(t)
\]</span> 因此使得两者最大化的划分是一样的。</p>
<p><span class="math inline">\(C(i|j)\)</span>表示将类<span class="math inline">\(j\)</span>误分为类<span class="math inline">\(i\)</span>的代价（非负），那么将节点<span class="math inline">\(t\)</span>标记为类<span class="math inline">\(i\)</span>的代价为： <span class="math display">\[
\sum_j C(i|j)p(j|t)
\]</span> <span class="math inline">\(j^*(t)\)</span>定义为使上式最小的类。<span class="math inline">\(r(t)\)</span>定义为上式的最小值。</p>
<p>令<span class="math inline">\(R(t)=r(t)p(t)\)</span>，定义树<span class="math inline">\(T\)</span>的误分类代价为： <span class="math display">\[
R(T)=\sum_{t\in\tilde{T}}R(t)
\]</span> 可以证明划分节点会降低代价： <span class="math display">\[
R(t)\ge R(t_L)+R(t_R)
\]</span> 但是这样一直划分下去，每个结点只包含一个类。这样会过拟合。一种方式是限制叶结点的数目。</p>
<p>令<span class="math inline">\(\alpha\ge0\)</span>，对于任意结点<span class="math inline">\(t\)</span>（不一定是叶结点），定义： <span class="math display">\[
R_\alpha(t)=R(t)+\alpha
\]</span> 对于树<span class="math inline">\(T\)</span>，定义： <span class="math display">\[
R_\alpha(T)=\sum_{t\in\tilde{T}}R(t)=R(T)+\alpha|\tilde{T}|
\]</span> 这样由于划分会增大<span class="math inline">\(\alpha|\tilde{T}|\)</span>，代价不一定会减小。</p>
<p>定义<span class="math inline">\(T\)</span>的pruned subtree <span class="math inline">\(T_1\)</span>，记为<span class="math inline">\(T_1\preceq T\)</span>：选取<span class="math inline">\(T\)</span>的一个结点<span class="math inline">\(t\)</span>，删除<span class="math inline">\(t\)</span>的所有后代结点（保留<span class="math inline">\(t\)</span>，因此所有叶结点仍然形成对输入空间的完整划分）。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>EM算法</title>
    <url>/2019/07/24/EM%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>EM算法就是含有隐变量的概率模型参数的极大似然估计法（或极大后验概率估计法）<br />
用<span class="math inline">\(x\)</span>表示观测变量（的数据），<span class="math inline">\(z\)</span>表示隐变量，<span class="math inline">\(\theta\)</span>表示需要估计的模型参数。<br />
给定观测数据<span class="math inline">\(x\)</span>，其似然函数为<span class="math inline">\(p(x|\theta)\)</span>，对数似然函数<span class="math inline">\(L(\theta) \triangleq \ln p(x|\theta)\)</span>。<br />
极大似然估计：<br />
<span class="math display">\[  
\max_{\theta}L(\theta)  
\]</span></p>
<h1 id="em算法">EM算法</h1>
<p>算法是迭代进行的，假设第<span class="math inline">\(n\)</span>轮迭代得到的参数估计为<span class="math inline">\(\theta_n\)</span>，希望下一轮迭代使得<span class="math inline">\(L(\theta)&gt;L(\theta_n)\)</span> <span class="math display">\[  
\begin{aligned}  
L(\theta)-L(\theta_n) &amp;=\ln \left(\sum_zp(z,x|\theta)\right)-\ln p(x|\theta_n)\\  
\end{aligned}  
\]</span> 对数函数是凹函数，满足Jensen不等式：<br />
<span class="math display">\[  
\log \left(\sum_j\lambda_jy_j\right)\geq \sum_j \lambda_j\log y_j  
\]</span> 其中<span class="math inline">\(\lambda_j\geq 0, \sum_j\lambda_j=1\)</span><br />
那么 <span class="math display">\[  
\begin{aligned}  
L(\theta)-L(\theta_n) &amp;=\ln \left(\sum_zp(z|x,\theta_n)\frac{p(z,x|\theta)}{p(z|x,\theta_n)}\right)-\ln p(x|\theta_n)\\  
&amp;\geq \sum_zp(z|x,\theta_n)\ln\frac{p(z,x|\theta)}{p(z|x,\theta_n)}-\ln p(x|\theta_n)\\  
&amp;=\sum_zp(z|x,\theta_n)\ln\frac{p(z,x|\theta)}{p(z|x,\theta_n)}-\left(\sum_zp(z|x,\theta_n)\right)\ln p(x|\theta_n)\\  
&amp;=\sum_zp(z|x,\theta_n)\ln\frac{p(z,x|\theta)}{p(z,x|\theta_n)}  
\end{aligned}  
\]</span> 即： <span class="math display">\[  
\begin{aligned}  
L(\theta)&amp;\geq L(\theta_n)+\sum_zp(z|x,\theta_n)\ln\frac{p(z,x|\theta)}{p(z,x|\theta_n)}\\  
&amp;\triangleq B(\theta,\theta_n)  
\end{aligned}  
\]</span> 也就是<span class="math inline">\(B(\theta,\theta_n)\)</span>是<span class="math inline">\(L(\theta)\)</span>的一个下界函数。而且容易看到：<br />
<span class="math display">\[  
B(\theta_n,\theta_n) = L(\theta_n)  
\]</span> 即自变量等于<span class="math inline">\(\theta_n\)</span>时，两个函数值是相等的。<br />
那么如果找一个<span class="math inline">\(\theta_{n+1}\)</span>，使得<span class="math inline">\(B(\theta_{n+1},\theta_n)\geq B(\theta_n,\theta_n)\)</span>，就能使<span class="math inline">\(L(\theta)\)</span>增大：<br />
<span class="math display">\[  
\begin{aligned}  
L(\theta_{n+1})&amp;\geq B(\theta_{n+1},\theta_n)\\  
&amp;\geq B(\theta_n,\theta_n)\\  
&amp;=L(\theta_n)  
\end{aligned}  
\]</span> 一种方法是使： <span class="math display">\[  
\theta_{n+1}=\operatorname{argmax} B(\theta,\theta_n)  
\]</span> 但是注意这样并不能保证<span class="math inline">\(L(\theta)\)</span>的增长也能极大化，这和<span class="math inline">\(L(\theta)\)</span>的具体形状有关。<br />
使<span class="math inline">\(B(\theta,\theta_n)\)</span>极大化，等价于极大化下面的式子，因为其他项为常数 <span class="math display">\[  
Q(\theta,\theta_n)\triangleq \sum_zp(z|x,\theta_n)\ln p(z,x|\theta)  
\]</span> 这个式子有着鲜明的含义：<br />
当有了<span class="math inline">\(x,\theta\)</span>，根据<span class="math inline">\(z\)</span>的概率分布<span class="math inline">\(p(z|x,\theta_n)\)</span>可以采样出<span class="math inline">\(z\)</span>，这样就有了完整的数据，可以做平常的极大似然估计。<br />
因此EM算法的步骤是：</p>
<ol type="1">
<li>E步：求完整数据对数似然的期望，这个期望是在概率分布<span class="math inline">\(p(z|x,\theta_n)\)</span>下求的。<br />
</li>
<li>M步：极大化，只是保证<span class="math inline">\(L(\theta)\)</span>增大的一种方式。</li>
</ol>
<p>在E步中，<span class="math inline">\(\ln p(x,z|\theta)\)</span>应该是很好算的，<span class="math inline">\(p(z|x,\theta)\)</span>也好算：<br />
<span class="math display">\[  
p(z|x,\theta)=\frac{p(z,x|\theta)}{p(x|\theta)}=\frac{p(z,x|\theta)}{\sum_{z&#39;}p(z&#39;,x|\theta)}  
\]</span></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>Hoeffding不等式</title>
    <url>/2019/09/07/Hoeffding%E4%B8%8D%E7%AD%89%E5%BC%8F/</url>
    <content><![CDATA[<p><strong>Markov不等式</strong>：随机变量<span class="math inline">\(Z\geq 0\)</span>。对于所有<span class="math inline">\(t\geq 0\)</span>，有 <span class="math display">\[
P(Z\geq t)\leq \frac{E[Z]}{t}
\]</span> 证明：</p>
<p><span class="math inline">\(Z\)</span>的最小最大值分别用<span class="math inline">\(a,b\)</span>表示 <span class="math display">\[
\begin{aligned}
P(Z\geq t)&amp;=\int_t^bp(z)dz\\
&amp;\leq \int_a^t\frac{z}{t}p(z)dz+\int_t^b\frac{z}{t}p(z)dz\\
&amp;=\frac{1}{t}\int_a^bzp(z)dz\\
&amp;=\frac{E[Z]}{t}
\end{aligned}
\]</span></p>
<p><strong>Chebyshev不等式</strong>：随机变量<span class="math inline">\(Z\)</span>均值为<span class="math inline">\(\mu\)</span>，方差为<span class="math inline">\(\sigma^2\)</span>（有限），对于<span class="math inline">\(t\geq0\)</span>，有 <span class="math display">\[
P(|Z-\mu|\geq t)\leq \frac{\sigma^2}{t^2}
\]</span> 证明： <span class="math display">\[
P(|Z-\mu|\geq t)=P((Z-\mu)^2\geq t^2)
\]</span> 然后应用Markov不等式。</p>
<p>令<span class="math inline">\(t=k\sigma\)</span>，得另一种常见形式： <span class="math display">\[
P(|Z-\mu|\geq k\sigma)\leq \frac{1}{k^2}
\]</span></p>
<p>我们想要更强的bound。</p>
<p>定义随机变量<span class="math inline">\(Z\)</span>的moment-generating function： <span class="math display">\[
M_Z(s)\triangleq E[e^{sZ}]
\]</span> <strong>Chernoff bound</strong>：对于任意<span class="math inline">\(t&gt;0\)</span>， <span class="math display">\[
P(Z\geq t)\leq \min_{s&gt;0}e^{-st}M_Z(s)
\]</span> 证明：</p>
<p>对任意<span class="math inline">\(s&gt;0\)</span>， <span class="math display">\[
\begin{aligned}
P(Z\geq t)&amp;=P(sZ\geq st)\\
&amp;=P(e^{sZ}\geq e^{st})\\
&amp;\leq e^{-st}E[e^{sZ}]\quad\text{Markov不等式}\\
&amp;=e^{-st}M_Z(s)
\end{aligned}
\]</span> 因为对任意<span class="math inline">\(s&gt;0\)</span>成立，自然小于最小的。</p>
<p><strong>Hoeffding‘s lemma</strong>：随机变量<span class="math inline">\(X\)</span>满足<span class="math inline">\(E[X]=0\)</span>，且<span class="math inline">\(a\leq X\leq b\)</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>，那么对于任意<span class="math inline">\(s\)</span>，有 <span class="math display">\[
E[e^{sX}]\leq \exp\left(\frac{s^2(b-a)^2}{8}\right)
\]</span> <a href="%5Bhttps://en.wikipedia.org/wiki/Hoeffding%27s_lemma%5D(https://en.wikipedia.org/wiki/Hoeffding&#39;s_lemma)">证明</a></p>
<p><strong>Hoeffding不等式</strong>：<span class="math inline">\(X_1,\dots,X_n\)</span>为独立随机变量，满足<span class="math inline">\(a_i\leq X_i\leq b_i\)</span>。定义<span class="math inline">\(S_n=\sum_{i=1}^n X_i\)</span>，那么对于<span class="math inline">\(t&gt;0\)</span>，有 <span class="math display">\[
P(S_n-E[S_n]\geq t)\leq e^{\frac{-2t^2}{\sum(b_i-a_i)^2}}\\
P(S_n-E[S_n]\leq -t)\leq e^{\frac{-2t^2}{\sum(b_i-a_i)^2}}
\]</span> 证明：</p>
<p>由Chernoff bound得 <span class="math display">\[
\begin{aligned}
P(S_n-E[S_n]\geq t)\leq\min_{s&gt;0}e^{-st}E\left[e^{s(S_n-E[S_n])}\right]
\end{aligned}
\]</span> 并且 <span class="math display">\[
\begin{aligned}
E\left[e^{s(S_n-E[S_n])}\right]&amp;=\Pi_{i=1}^nE\left[e^{s(X_i-E[X_i])}\right]\quad \text{由于$X_i$相互独立}\\
&amp;\leq\Pi_{i=1}^n \exp\left(\frac{s^2(b_i-a_i)^2}{8}\right)\quad\text{由Hoeffding&#39;s lemma}
\end{aligned}
\]</span> 然后只要求得 <span class="math display">\[
\text{argmin}_{s&gt;0}-st+\frac{s^2}{8}\sum_{i=1}^n(b_i-a_i)^2
\]</span> 代入就可得证。</p>
<p>由第一个公式及<span class="math inline">\(Z_i=-X_i\in[-b_i,-a_i]\)</span>就得第二个公式。两个式子组合起来得到： <span class="math display">\[
P(|S_n-E[S_n]|\geq t)\leq 2e^{\frac{-2t^2}{\sum(b_i-a_i)^2}}
\]</span> 如果<span class="math inline">\(X_i\)</span>服从伯努利分布<span class="math inline">\(\text{Ber}(p)\)</span>，那么<span class="math inline">\(a_i=0,b_i=1\)</span>，<span class="math inline">\(S_n\)</span>服从二项分布<span class="math inline">\(\text{ binom}(n,p)\)</span>，<span class="math inline">\(E[s_n]=np\)</span>。 <span class="math display">\[
P(|S_n-np|&gt;t)=p\left(\left|\frac{S_n}{n}-p\right|&gt;\frac{t}{n}\right)\leq 2e^{\frac{-2t^2}{n}}
\]</span> 令<span class="math inline">\(\frac{t}{n}=\epsilon\)</span>，得： <span class="math display">\[
p\left(\left|\frac{1}{n}\sum_{i=1}^nX_i-p\right|&gt;\epsilon\right)\leq 2e^{-2n\epsilon^2}
\]</span></p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>由<span class="math inline">\(E[X]=0\)</span>可得<span class="math inline">\(a\leq 0\leq b\)</span><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>数学</category>
        <category>概率统计</category>
      </categories>
  </entry>
  <entry>
    <title>Hough变换</title>
    <url>/2019/08/10/Hough%E5%8F%98%E6%8D%A2/</url>
    <content><![CDATA[<h1 id="检测直线">检测直线</h1>
<p>给定二值图像中的<span class="math inline">\(n\)</span>个点，要找到图像中的直线。一种方法是枚举所有可能的<span class="math inline">\(n*(n-1)/2\)</span>条直线，然后检测每个点是否足够靠近线。如果足够靠近，就给这条线投一票。最后票数多的直线很可能是真正的直线。这样的复杂度是<span class="math inline">\(n^3\)</span>的，对于一般的图片大小并不实用。</p>
<h2 id="参数空间方法">参数空间方法</h2>
<p>Hough变换的思想最初是Hough在一篇专利中提出的。 考虑<span class="math inline">\(xy\)</span>平面上的一点<span class="math inline">\((x_i,y_i)\)</span>，假设通过这个点的某条直线的斜率为<span class="math inline">\(a\)</span>，截距为<span class="math inline">\(b\)</span>，那么<span class="math inline">\(y_i = ax_i+b\)</span>。将式子写成<span class="math inline">\(b=-x_ia+y_i\)</span>，即通过给定点的直线的斜率和截距满足一定关系。在<span class="math inline">\(ab\)</span>平面（参数空间），这是一条直线。另一个点<span class="math inline">\((x_j,y_j)\)</span>在参数空间也有一条关联的直线。如果这两条直线不平行，那么会交于一点<span class="math inline">\((a&#39;,b&#39;)\)</span>。<span class="math inline">\((a&#39;,b&#39;)\)</span>既是通过<span class="math inline">\((x_i,y_i)\)</span>的某条直线的参数，又是通过<span class="math inline">\((x_j,y_j)\)</span>的某条直线的参数，显然这条直线就是连接<span class="math inline">\((x_i,y_i)\)</span>，<span class="math inline">\((x_j,y_j)\)</span>的直线。 以上的方案有一点缺陷。我们知道只要<span class="math inline">\((x_i,y_i)\)</span>，<span class="math inline">\((x_j,y_j)\)</span>不是同一点，总能唯一确定一条直线。然而参数空间却有可能无法表示对应的参数值。也就是参数空间的两条直线平行的时候，无法求得参数。此时两条直线斜率相同：<span class="math inline">\(-x_i=-x_j\)</span>。也就是当两点的<span class="math inline">\(x\)</span>坐标相同时，连线是一条竖直的线，斜率无穷大，无法在参数空间表示。</p>
<h2 id="法线表示">法线表示</h2>
<p>针对上述问题，我们现在用的Hough变换版本是Hart（和Duda）1972年在《Use of the Hough transformation to detect lines and curves in pictures》这篇论文中提出的。<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> 它利用的是直线的另一种表示：法线表示。 <span class="math display">\[
x\cos\theta+y\sin\theta = \rho
\]</span> 其中<span class="math inline">\(\theta\)</span>是直线的法线和<span class="math inline">\(x\)</span>轴的夹角，<span class="math inline">\(\rho\)</span>是原点到直线的距离（根据对<span class="math inline">\(\theta\)</span>取值范围的规定，可能为负）。把上式写成向量<span class="math inline">\((x,y)\)</span>与单位法向量<span class="math inline">\((\cos\theta,\sin\theta)\)</span>的点积，就很显然。从几何上容易看出，<span class="math inline">\(\rho\)</span>的最大取值为图像的对角线长度，因此不会有斜率-截距表示法中的无穷大问题。 图像中的一个点关联着<span class="math inline">\(\rho\theta\)</span>参数空间中的一条正弦曲线。一条直线上的点对应的正弦曲线族在<span class="math inline">\(\rho\theta\)</span>空间中会交于同一点。如果每个<span class="math inline">\((\theta,\rho)\)</span>关联着一个累加器，其数值是参数空间中所有正弦曲线通过它的次数，那么某条直线对应的累积器数值就是直线上点的个数。我们无法枚举无限多的<span class="math inline">\((\theta,\rho)\)</span>，Hough变换的做法是将<span class="math inline">\(\rho\theta\)</span>空间按一定的分辨率网格化。对于图像中每个点，按设定的分辨率枚举所有的<span class="math inline">\(\theta\)</span>，按<span class="math inline">\(\rho = x\cos\theta+y\sin\theta\)</span> 得到对应的<span class="math inline">\(\rho\)</span>，根据设定的<span class="math inline">\(\rho\)</span>的分辨率得到对应网格，其累加器加一。最后把数值大的累加器对应的参数认定为直线。</p>
<h2 id="opencv中的实现">opencv中的实现</h2>
<p>opencv中<span class="math inline">\(\theta\)</span>的取值范围为0到180度，那么<span class="math inline">\(\rho\)</span>是有可能为负的。其范围为<span class="math inline">\(-D\leq\rho\leq D\)</span>，其中<span class="math inline">\(D\)</span>为对角线长。 实现在<code>hough.cpp</code>的<code>HoughLinesStandard</code>函数中。 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> max_rho = width + height;</span><br><span class="line"><span class="keyword">int</span> min_rho = -max_rho;</span><br><span class="line"><span class="keyword">int</span> numrho = <span class="built_in">cvRound</span>(((max_rho - min_rho) + <span class="number">1</span>) / rho);</span><br></pre></td></tr></table></figure> 可以看到它取的<span class="math inline">\(\rho\)</span>的最大值为宽加高，保证了大于对角线长。 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// stage 1. fill accumulator</span></span><br><span class="line"><span class="keyword">for</span>( i = <span class="number">0</span>; i &lt; height; i++ )</span><br><span class="line">    <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; width; j++ )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>( image[i * step + j] != <span class="number">0</span> )</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> n = <span class="number">0</span>; n &lt; numangle; n++ )</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">int</span> r = <span class="built_in">cvRound</span>( j * tabCos[n] + i * tabSin[n] );</span><br><span class="line">                r += (numrho - <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line">                accum[(n+<span class="number">1</span>) * (numrho+<span class="number">2</span>) + r+<span class="number">1</span>]++;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure> <code>int r = cvRound( j * tabCos[n] + i * tabSin[n] );</code>表示<span class="math inline">\(r = \frac{x\cos\theta+y\sin\theta}{\Delta\rho}\)</span>，其中<span class="math inline">\(\Delta \rho\)</span>为<span class="math inline">\(\rho\)</span>的分辨率。这里<span class="math inline">\(r\)</span>取值范围在<span class="math inline">\(-\frac{D}{\Delta \rho}\)</span>和<span class="math inline">\(\frac{D}{\Delta \rho}\)</span>之间，<code>r += (numrho - 1) / 2;</code>是为了把值shift到非负范围才能作为累加器的列索引。（累加器的行索引为<span class="math inline">\(\theta\)</span>，列索引为<span class="math inline">\(\rho\)</span>）。 下面的代码则是相应地还原回真正的<span class="math inline">\(\rho\)</span>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> n = <span class="built_in">cvFloor</span>(idx*scale) - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> r = idx - (n+<span class="number">1</span>)*(numrho+<span class="number">2</span>) - <span class="number">1</span>;</span><br><span class="line">line.rho = (r - (numrho - <span class="number">1</span>)*<span class="number">0.5f</span>) * rho;</span><br></pre></td></tr></table></figure>
<h3 id="其他实现细节">其他实现细节</h3>
<ol type="1">
<li>在累加器矩阵中只会保留局部极大值，也就是比上下左右的累积器的值都要大才有可能输出，这样可以去掉非常接近的线。</li>
<li>结果是按累加器的值从大到小排序的。</li>
</ol>
<h3 id="指定theta范围">指定<span class="math inline">\(\theta\)</span>范围</h3>
<p>在做跟踪的时候，可能只需要某个范围的<span class="math inline">\(\theta\)</span>中做检测。<code>Houghlines</code>中可以指定最小和最大的<span class="math inline">\(\theta\)</span>。如果是以两个点表示的直线，先要得到<span class="math inline">\(\theta\)</span>值。由 <span class="math display">\[
x_1\cos(\theta)+y_1\sin(\theta) = x_2\cos(\theta)+y_2\sin(\theta) = \rho
\]</span> 得： <span class="math display">\[
\tan\theta = \frac{x_1-x_2}{y_2-y_1}
\]</span> 又因为在opencv中<span class="math inline">\(\theta\in [0,\pi]\)</span>，因此 <span class="math display">\[
\theta =
        \begin{cases}
        \arctan(\frac{x_1-x_2}{y_2-y_1}) ,  &amp; \text{if $\arctan(\frac{x_1-x_2}{y_2-y_1})\geq 0$ } \\
        \pi - \arctan(\frac{x_1-x_2}{y_2-y_1}), &amp; \text{else}
        \end{cases}
\]</span> 直线和<span class="math inline">\(\theta\)</span>对应关系如下图，可见在竖直线时<span class="math inline">\(\theta\)</span>不连续变化。 <img src="/images/hough-theta.png" alt="对应关系" /></p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>有兴趣的可以看Hart写的《How the Hough transform was invented》了解这段历史<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title>Iterative Closest Point</title>
    <url>/2019/08/10/Iterative%20Closest%20Point/</url>
    <content><![CDATA[<h1 id="问题">问题</h1>
<p>要把三维空间中的点集<span class="math inline">\(\{p_1,p_2,\cdots,p_n\}\)</span>通过旋转、平移和点集<span class="math inline">\(\{q_1,q_2,\cdots,q_n\}\)</span>匹配起来。<span class="math inline">\(p\)</span>可能是预先给定的模型，而<span class="math inline">\(q\)</span>是在另一个坐标系中观察的结果，匹配就是要找到两个坐标系的转换关系。</p>
<h1 id="给定对应关系的情况">给定对应关系的情况</h1>
<p>先考虑简单的情形，即给定了两个集合中点的对应关系，<span class="math inline">\(p_i\)</span>对应<span class="math inline">\(q_i\)</span>。 定义两个点集间的距离为： <span class="math display">\[
\sum_{i=1}^n\|p_i-q_i\|^2
\]</span> 我们的目标是找到旋转矩阵<span class="math inline">\(R\)</span>、平移向量<span class="math inline">\(b\)</span>，使得<span class="math inline">\(p\)</span>变换后与<span class="math inline">\(q\)</span>的距离最小 <span class="math display">\[
\min_{R,b}\sum_{i=1}^n\|Rp_i+b-q_i\|^2
\]</span> 目标函数对<span class="math inline">\(b\)</span>求导并令导数为<span class="math inline">\(\mathbf{0}\)</span>，得： <span class="math display">\[
b=\bar{q}-R\bar{p}
\]</span> 其中 <span class="math display">\[
\bar{p}=\frac{1}{n}\sum_{i=1}^np_i\\
\bar{q}=\frac{1}{n}\sum_{i=1}^nq_i\\
\]</span> 分别是点集的“质心”。 将<span class="math inline">\(b\)</span>的表达式代入目标函数，得到： <span class="math display">\[
\sum_{i=1}^n\|Rp_i+b-q_i\|=\sum_{i=1}^n\|Rp_i&#39;-q_i&#39;\|^2
\]</span> 其中： <span class="math display">\[
p_i&#39;=p_i-\bar{p}\\
q_i&#39;=q_i-\bar{q}
\]</span> 为点相对于质心的坐标。 <span class="math display">\[
\begin{aligned}
\sum_{i=1}^n\|Rp_i&#39;-q_i&#39;\|^2&amp;=\sum_{i=1}^n(Rp_i&#39;\cdot Rp_i&#39;)-2\sum_{i=1}^n(Rp_i&#39;\cdot q_i&#39;)+\sum_{i=1}^n(q_i&#39;\cdot q_i&#39;)\\
&amp;=\sum_{i=1}^n(\|p_i&#39;\|^2+\|q_i&#39;\|^2)-2\sum_{i=1}^nRp_i&#39;\cdot q_i&#39;
\end{aligned}
\]</span> 上式中<span class="math inline">\(Rp_i&#39;\cdot Rp_i&#39;=\|p_i&#39;\|^2\)</span>是因为旋转不改变向量长度。 上式第一项与<span class="math inline">\(R\)</span>无关，因此只要最小化第二项。或者等价地求如下最大化： <span class="math display">\[
\max_R\sum_{i=1}^nRp_i&#39;\cdot q_i&#39;
\]</span> 下面用两种方法来求解。 采用新符号<span class="math inline">\(x_i=p_i&#39;\)</span>，<span class="math inline">\(y_i=q_i&#39;\)</span></p>
<h2 id="svd">SVD</h2>
<p>用SVD推导时似乎常引用资料[4]，不过我下面采用资料[3]中的推导，因为更简单直接。 <span class="math display">\[
\begin{aligned}
\sum_{i=1}^nRx_i\cdot y_i&amp;=\sum_{i=1}^ny_i^TRx_i\\
&amp;=tr(\sum_{i=1}^ny_i^TRx_i) \quad\text{标量=标量的迹}\\
&amp;=tr(\sum_{i=1}^nx_iy_i^TR) \quad\text{因为tr(AB)=tr(BA)}\\
&amp;=tr(CR) \quad C\triangleq\sum_{i=1}^nx_iy_i^T\\
&amp;=tr(U\Lambda V^TR) \quad\text{SVD分解：$C=U\Lambda V^T$}\\
&amp;=tr(\Lambda V^TRU) \\
&amp;=tr(\Lambda T) \quad T\triangleq V^TRU\\
&amp;=\sum_{i=1}^3\lambda_iT_{ii}
\end{aligned}
\]</span> 由于<span class="math inline">\(V,R,U\)</span>都是正交矩阵，因此<span class="math inline">\(T\)</span>是正交矩阵，即每一列的长度为1，则<span class="math inline">\(T_{ii}\leq 1\)</span>，因此： <span class="math display">\[
\sum_{i=1}^3\lambda_iT_{ii}\leq\sum_{i=1}^3\lambda_i
\]</span> 当<span class="math inline">\(T_{ii}=1\)</span>时等号成立，此时<span class="math inline">\(T\)</span>的其他元素为0，即<span class="math inline">\(T=I\)</span>。由<span class="math inline">\(V^TRU=T=I\)</span>，得旋转矩阵： <span class="math display">\[
R=VU^T
\]</span> 当然旋转矩阵应该满足<span class="math inline">\(\det(R)=1\)</span>。如果求得<span class="math inline">\(\det (VU^T)=-1\)</span>，那说明<span class="math inline">\(T\)</span>不能等于<span class="math inline">\(I\)</span>。 <span class="math display">\[
\begin{aligned}
\det(T)&amp;=\det(V^TRU) \\
&amp;=\det(UV^TR) \\
&amp;=\det(UV^T)\det(R) \\
&amp;=-1
\end{aligned}
\]</span> 在这种情况下[3]中说</p>
<blockquote>
<p>It is easy to see what the second largest value is</p>
</blockquote>
<p>就是<span class="math inline">\(T_{11}=T_{22}=1,T_{33}=-1\)</span>，不过我没有看出来为什么是这样。。 那相应的<span class="math inline">\(R\)</span>变成 <span class="math display">\[
R=V\begin{bmatrix}
    1 &amp; &amp; \\
    &amp; 1 &amp; \\
    &amp; &amp; -1
  \end{bmatrix}U^T
\]</span> [4]中说如果是有点集共面因而<span class="math inline">\(\lambda_3=0\)</span>（因为此时<span class="math inline">\(C\)</span>不是满秩），那么对结果没有影响。如果<span class="math inline">\(C\)</span>满秩而反射（即<span class="math inline">\(\det(R)=-1\)</span>）是最优解，那么很可能数据中有outlier。</p>
<h2 id="四元数">四元数</h2>
<p>用<span class="math inline">\(q\)</span>来表示四元数。 由四元数表示旋转的方式得到下面的目标函数： <span class="math display">\[
\sum_{i=1}^n(qx_iq^*)\cdot y_i
\]</span> 可以<a href="#四元数性质证明">证明</a>： <span class="math display">\[
(qx_iq^*)\cdot y_i=(qx_i)\cdot(y_iq)
\]</span> 因此： <span class="math display">\[
\begin{aligned}
\sum_{i=1}^n(qx_iq^*)\cdot y_i &amp;=\sum_{i=1}^n(qx_i)\cdot(y_iq)\\
&amp;=\sum_{i=1}^n([x_i]_Rq)\cdot([y_i]_Lq)\\
&amp;=\sum_{i=1}^nq^T[x_i]_R^T[y_i]_Lq\\
&amp;=q^T\left(\sum_{i=1}^n[x_i]_R^T[y_i]_L\right)q\\
&amp;\triangleq q^TMq
\end{aligned}
\]</span> 可以<a href="#对称阵验证">验证</a><span class="math inline">\([x_i]_R^T[y_i]_L\)</span>是对称阵，因此<span class="math inline">\(M\)</span>是对称阵。 那剩下的就是线代的标准内容了，<span class="math inline">\(q^TMq\)</span>能取得的最大值为<span class="math inline">\(M\)</span>的最大的特征值，对应的<span class="math inline">\(q\)</span>为对应的归一化的特征向量。</p>
<h1 id="icp">ICP</h1>
<p>接下来就是不知道对应点的情况，也就是ICP要解决的。 这部分比较简单。既然不知道<span class="math inline">\(p_i\)</span>对应的<span class="math inline">\(q\)</span>，那我可以把<span class="math inline">\(p_i\)</span>与点集<span class="math inline">\(q\)</span>中离它最近的点对应。假设这是在第<span class="math inline">\(k\)</span>轮，这样得到的距离记为<span class="math inline">\(c_k\)</span>（c代表correspondence）。 有了对应关系，就可以按上面的方法做配准，记得到的距离为<span class="math inline">\(d_k\)</span>。因为我们做了最小化，显然 <span class="math display">\[
d_k\leq c_k
\]</span> 对于变换后的点集<span class="math inline">\(p\)</span>中的每个点，我们再在<span class="math inline">\(q\)</span>中找距离最近的点。这样显然每个<span class="math inline">\(p_i\)</span>对应的距离都只可能减小，因此总的距离也只会减小，即： <span class="math display">\[
c_{k+1}\leq d_k
\]</span> 这样， <span class="math display">\[
0\leq d_{k+1} \leq c_{k+1} \leq d_k\leq c_k
\]</span> 单调下降有下界，因此会收敛到一个局部极小值。 实现时设定一个阈值<span class="math inline">\(\tau\)</span>，当满足如下条件时停止迭代。 <span class="math display">\[
d_k-d_{k+1}&lt;\tau
\]</span></p>
<h1 id="附录">附录</h1>
<h2 id="四元数性质证明">四元数性质证明</h2>
<p>只要证明： <span class="math display">\[
(pq)\cdot r=p\cdot(rq^*)
\]</span> 然后代入 <span class="math display">\[
p\leftarrow qx_i\\
q\leftarrow q^*\\
r\leftarrow y_i
\]</span> 就得证。 由于 <span class="math display">\[
(pq)\cdot r = ([q]_Rp)^Tr=p^T[q]_R^Tr\\
p\cdot(rq^*)=p^T[q^*]_Rr
\]</span> 因此只要证： <span class="math display">\[
[q]_R^T=[q^*]_R
\]</span> 而这是显然的。</p>
<h2 id="对称阵验证">对称阵验证</h2>
<p>因为<span class="math inline">\(x\)</span>,<span class="math inline">\(y\)</span>都是虚四元数， <span class="math display">\[
\begin{aligned}
\left[x\right]_R^\top[y]_L&amp;=\begin{bmatrix}
0 &amp; \mathbf{x}_v^\top\\
-\mathbf{x}_v &amp; [\mathbf{x}_v]_{\times}
\end{bmatrix}\begin{bmatrix}
0 &amp; -\mathbf{y}_v^\top\\
\mathbf{y}_v &amp; [\mathbf{y}_v]_{\times}
\end{bmatrix}\\
&amp;=\begin{bmatrix}
\mathbf{x}_v^\top\mathbf{y}_v &amp; \mathbf{x}_v^\top[\mathbf{y}_v]_{\times}\\
[\mathbf{x}_v]_{\times}\mathbf{y}_v &amp; \mathbf{x}_v\mathbf{y}_v^\top+[\mathbf{x}_v]_{\times}[\mathbf{y}_v]_{\times}
\end{bmatrix}
\end{aligned}
\]</span> 其它都比较明显，只要证明 <span class="math display">\[
\mathbf{x}_v\mathbf{y}_v^\top+[\mathbf{x}_v]_{\times}[\mathbf{y}_v]_{\times}
\]</span> 是对称阵。由于 <span class="math display">\[
[\mathbf{x}_v]_{\times}[\mathbf{y}_v]_{\times}=\mathbf{y}_v\mathbf{x}_v^\top-(\mathbf{x}_v\cdot\mathbf{y}_v)I
\]</span> 因此结论成立。</p>
<h1 id="参考资料">参考资料</h1>
<ol type="1">
<li><p><a href="http://web.cs.iastate.edu/~cs577/handouts/quaternion.pdf">四元数用于求解shape registration</a></p></li>
<li><p><a href="https://ieeexplore.ieee.org/document/121791">A Method for Registration of 3-D Shapes</a>（ICP原始文献）</p></li>
<li><p><a href="https://cnx.org/contents/HV-RsdwL@23/Molecular-Distance-Measures#MatrixAlignment">SVD方法推导</a></p></li>
<li><p><a href="https://ieeexplore.ieee.org/document/4767965">Least-Squares Fitting of Two 3-D Point Sets</a> （另一种SVD推导）</p></li>
<li><p><a href="http://people.csail.mit.edu/bkph/papers/Absolute_Orientation.pdf">Closed-form solution of absolute orientation using unit quaternions</a> （四元数推导的原始文献）</p></li>
</ol>
]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>ICP</tag>
        <tag>SVD</tag>
        <tag>四元数</tag>
      </tags>
  </entry>
  <entry>
    <title>Karatsuba算法</title>
    <url>/2019/10/13/Karatsuba%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>Karatsuba算法是一种快速乘法算法。设<span class="math inline">\(x,y\)</span>均为<span class="math inline">\(n\)</span>为整数（这里假设<span class="math inline">\(n\)</span>为偶数），求<span class="math inline">\(x\cdot y\)</span>。直接乘复杂度为<span class="math inline">\(O(n^2)\)</span>。</p>
<p>用分治法，其中 <span class="math display">\[
x=a\cdot 10^{n/2}+b\\
y=c\cdot 10^{n/2}+d
\]</span> 那么 <span class="math display">\[
\begin{align}
x\cdot y &amp;= (a\cdot 10^{n/2}+b)(c\cdot 10^{n/2}+d)\\
&amp;=ac\cdot10^n+(ad+bc)\cdot10^{n/2}+bd
\end{align}
\]</span> 这里是4次大小为<span class="math inline">\(n/2\)</span>的乘法，并不能降低复杂度。关键在于 <span class="math display">\[
ad+bc=(a+b)(c+d)-ac-bd
\]</span> 这样就只有3次乘法，降低了复杂度。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title>apache commons math的一些记录</title>
    <url>/2019/11/10/ResizableDoubleArray/</url>
    <content><![CDATA[<p><code>ResizableDoubleArray</code>内部是一个数组，并且通过<code>startIndex</code>和<code>numElements</code>维护一个窗口。在<code>addElementRolling</code>时，除了<code>numElements</code>+1，<code>startIndex</code>也+1。默认情况下数组扩展时长度变为2倍，如果数组长度<code>/</code>元素个数大于2.5，则收缩数组。</p>
<p><code>DescriptiveStatistics</code>内部使用<code>ResizableDoubleArray</code>，支持滑动窗口。计算统计量时，都是针对窗口当场计算，如计算方差：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getVariance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> apply(varianceImpl);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(UnivariateStatistic stat)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// eDA为内部的ResizableDoubleArray</span></span><br><span class="line">    <span class="keyword">return</span> eDA.compute(stat);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每种统计量实现为一个类，实现如下方法，在<code>ResizableDoubleArray</code>的<code>compute</code>方法中调用：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">evaluate</span><span class="params">(<span class="keyword">double</span>[] array,</span></span></span><br><span class="line"><span class="function"><span class="params">                <span class="keyword">int</span> startIndex,</span></span></span><br><span class="line"><span class="function"><span class="params">                <span class="keyword">int</span> numElements)</span></span>;</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>AdaBoost</title>
    <url>/2019/10/30/adaboost/</url>
    <content><![CDATA[<h1 id="算法推导">算法推导</h1>
<p>目标函数是基函数的线性组合： <span class="math display">\[
f(x)=\sum_{m=1}^M\alpha_m b(x;\beta_m)
\]</span> loss函数最小化： <span class="math display">\[
\min_{\{\alpha_m,\beta_m\}_i^M}\sum_{i=1}^NL\left(y_i,\sum_{m=1}^M\alpha_m b(x_i;\beta_m)\right)
\]</span> 但是这个很难求。Forward Stagewise方法每次只对一组<span class="math inline">\((\alpha_m,\beta_m)\)</span>做最小化，求完之后这组参数就固定了。</p>
<p>adaboost中<span class="math inline">\(y\in\{-1,1\}\)</span>，loss函数为指数函数： <span class="math display">\[
L(y,f(x))=e^{-yf(x)}
\]</span> 基函数（分类器）为<span class="math inline">\(G_m(x)\in\{-1,1\}\)</span>。</p>
<p>由前<span class="math inline">\(m\)</span>个基函数得到的分类器为： <span class="math display">\[
f_m(x)=f_{m-1}(x)+\alpha_mG_m(x)
\]</span> 这里<span class="math inline">\(\alpha_m&gt;0\)</span>。</p>
<p>由Forward Stagewise方法， <span class="math display">\[
\begin{align}
(\alpha_m,G_m)&amp;=\arg\min_{\alpha,G} L(y,f_m(x))\\
&amp;=\arg\min_{\alpha,G}\sum_{i=1}^N\exp[-y_i(f_{m-1}(x_i)+\alpha G(x_i))]\\
&amp;=\arg\min_{\alpha,G}\sum_{i=1}^Nw_m^{(i)}\exp(-y_i\alpha G(x_i))\quad\left(w_m^{(i)}\triangleq \exp(-y_if_{m-1}(x_i))\right)
\end{align}
\]</span> <span class="math inline">\(w_m^{(i)}\)</span>和<span class="math inline">\(\alpha,G(x)\)</span>无关，可以看成是数据点的权重。初始时所有数据点的权重相等，都为<span class="math inline">\(\frac{1}{N}\)</span>。权重可以递推更新： <span class="math display">\[
w_{m+1}^{(i)}=\frac{w_m^{(i)}}{Z_m}\exp(-y_i\alpha_mG_m(x_i))
\]</span> 其中<span class="math inline">\(Z_m=\sum_{i=1}^Nw_m^{(i)}\exp(-y_i\alpha_mG_m(x_i))=L(y,f_m(x))\)</span>是规范化因子，保证<span class="math inline">\(w_m\)</span>成为概率分布。</p>
<p>上式又可写为： <span class="math display">\[
w_{m+1}^{(i)}=\begin{cases} \frac{w_m^{(i)}}{Z_m}e^{-\alpha_m}, &amp; G_m(x_i)=y_i \\ \frac{w_m^{(i)}}{Z_m}e^{\alpha_m}, &amp; G_m(x_i)\neq y_i \end{cases}
\]</span></p>
<p>可见被<span class="math inline">\(G_m(x)\)</span>误分类的样本在下一轮中权重扩大，使得分类器能重点关注这些样本。</p>
<p>上面的loss函数可化为（为简化，符号中去掉了<span class="math inline">\(m\)</span>）： <span class="math display">\[
e^{-\alpha}\sum_{y_i=G(x_i)}w^{(i)}+e^{\alpha}\sum_{y_i\neq G(x_i)}w^{(i)}
\]</span> 加权误分类率<span class="math inline">\(e_m=\sum_{y_i\neq G(x_i)}w^{(i)}\)</span>，上式变为： <span class="math display">\[
(e^\alpha-e^{-\alpha})e_m+e^{-\alpha}
\]</span> 给定<span class="math inline">\(\alpha\)</span>，上式第二项为常数，第一项前面的系数非负，因此： <span class="math display">\[
\arg\min_{G(x)} L = \arg\min_{G(x)}e_m
\]</span> 即<span class="math inline">\(G_m(x)\)</span>要在加权数据上误分类率最低。</p>
<p>对<span class="math inline">\(\alpha\)</span>求最小化，解得： <span class="math display">\[
\alpha = \frac{1}{2}\ln\frac{1-e_m}{e_m}
\]</span></p>
<p>对于弱分类器<span class="math inline">\(G_m(x)\)</span>，要求其要好于随机猜，即<span class="math inline">\(e_m=\frac{1}{2}-\gamma_m&lt;\frac{1}{2}\)</span>。</p>
<p>将<span class="math inline">\(\alpha\)</span>带入<span class="math inline">\(L(y,f_m(x))\)</span>，得： <span class="math display">\[
L(y,f_m(x))=Z_m=2\sqrt{e_m(1-e_m)}
\]</span></p>
<h1 id="训练误差分析">训练误差分析</h1>
<p>训练集分类错误率： <span class="math display">\[
\frac{1}{N}\sum_{i=1}^NI(\text{sign}(f(x_i))\neq y_i)
\]</span> 其中<span class="math inline">\(I(\cdot)\)</span>为indicator function。</p>
<p>由于 <span class="math display">\[
I\left(\text{sign}(f(x_i))\neq y_i\right)=I(y_if(x_i)\le 0)\le \exp(-y_if(x_i))
\]</span></p>
<p>因此推导<span class="math inline">\(\frac{1}{N}\sum_{i=1}^N\exp(-y_if(x_i))\)</span>的界。 <span class="math display">\[
\begin{align}
\frac{1}{N}\sum_i\exp(-y_if(x_i))&amp;=\frac{1}{N}\sum_i\exp\left(-\sum_{m=1}^My_i\alpha_mG_m(x_i)\right)\\
&amp;=\sum_iw_1^{(i)}\prod_{m=1}^M\exp(-y_i\alpha_mG_m(x_i))\quad(w_1^{(i)}=\frac{1}{N})\\
&amp;=\sum_iw_1^{(i)}\exp(-y_i\alpha_1G_1(x_i))\prod_{m=2}^M\exp(-y_i\alpha_mG_m(x_i))\\
&amp;=\sum_iZ_1w_2^{(i)}\prod_{m=2}^M\exp(-y_i\alpha_mG_m(x_i))\\
&amp;=Z_1\sum_iw_2^{(i)}\prod_{m=2}^M\exp(-y_i\alpha_mG_m(x_i))\\
&amp;=\cdots\\
&amp;=\prod_{m=1}^MZ_m\\
&amp;=\prod_{m=1}^M2\sqrt{e_m(1-e_m)}\\
&amp;=\prod_{m=1}^M\sqrt{1-4\gamma_m^2}\\
&amp;\le\exp\left(-2\sum_{i=1}^M\gamma_m^2\right)
\end{align}
\]</span> 因此如果存在<span class="math inline">\(\gamma&gt;0\)</span>，使得对所有<span class="math inline">\(m\)</span>有<span class="math inline">\(\gamma_m\ge \gamma\)</span>，则： <span class="math display">\[
\frac{1}{N}\sum_{i=1}^NI(\text{sign}(f(x_i))\neq y_i)\le e^{-2M\gamma^2}
\]</span> 这表明训练误差以指数速度下降，最终降为0。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>naive bayes</title>
    <url>/2019/10/30/naive%20bayes/</url>
    <content><![CDATA[<p>生成模型：<span class="math inline">\(p(X|Y)\)</span>描述了如何根据目标属性<span class="math inline">\(Y\)</span>来生成随机实例<span class="math inline">\(X\)</span>。</p>
<p>目的是计算<span class="math inline">\(p(Y|X_1\dots X_n)\)</span>来对<span class="math inline">\(Y\)</span>分类。</p>
<p>这里并不存在条件独立，即<span class="math inline">\(p(Y|X_1\dots X_n)\ne\prod p(Y|X_i)\)</span>，那样不是证据越多反而概率越小了吗？</p>
<p>所以先通过Bayes定理： <span class="math display">\[
p(Y|X_1\dots X_n)=\frac{p(Y)p(X_1\dots X_n|Y)}{p(X_1\dots X_n)}
\]</span></p>
<p>假设<span class="math inline">\(Y,X_i\)</span>都是二值的，那么<span class="math inline">\(p(X_1\dots X_n|Y)\)</span>总共有<span class="math inline">\(2(2^n-1)\)</span>个参数，要估计这些参数需要的数据太多。因此要引入其他假设。</p>
<p>这里就用条件独立： <span class="math display">\[
p(X_i|X_j,Y)=p(X_i|Y)
\]</span> 那么 <span class="math display">\[
p(X_1\dots X_n|Y)=\prod_{i=1}^np(X_i|Y)
\]</span> 参数数量降为<span class="math inline">\(2n\)</span>.</p>
<p>如果要求最可能的<span class="math inline">\(Y\)</span>，由于分母和<span class="math inline">\(Y\)</span>无关，因此： <span class="math display">\[
Y\leftarrow \arg\max_{y_k}p(Y=y_k)\prod_ip(X_i|Y=y_k)
\]</span> 参数的极大似然估计（通过拉格朗日乘子推导？）： <span class="math display">\[
\hat{p}(X_i=x_{ij})|Y=y_k)=\frac{\#D\{X_i=x_{ij} \bigwedge Y=y_k\}}{\#D\{Y=y_k\}}
\]</span> <span class="math inline">\(x_{ij}\)</span>表示<span class="math inline">\(X_i\)</span>取第<span class="math inline">\(j\)</span>个值，<span class="math inline">\(\#D\{x\}\)</span>表示数据集中满足条件<span class="math inline">\(x\)</span>的数据数量。</p>
<p>如果没有满足条件的数据，相应的概率会估计为0。可以通过虚拟的数据来平滑： <span class="math display">\[
\hat{p}(X_i=x_{ij})|Y=y_k)=\frac{\#D\{X_i=x_{ij} \bigwedge Y=y_k\}+l}{\#D\{Y=y_k\}+lJ}
\]</span> 其中<span class="math inline">\(J\)</span>是<span class="math inline">\(X_i\)</span>能取的值的个数。如果<span class="math inline">\(l=1\)</span>，称为Laplace平滑。 <span class="math display">\[
\hat{p}(Y=y_k)=\frac{\#D\{Y=y_k\}}{|D|}
\]</span> 平滑的估计： <span class="math display">\[
\hat{p}(Y=y_k)=\frac{\#D\{Y=y_k\}+l}{|D|+lK}
\]</span> 其中<span class="math inline">\(K\)</span>为<span class="math inline">\(Y\)</span>能取的值的个数。</p>
<h2 id="naive-bayes-for-continuous-inputs">Naive Bayes for Continuous Inputs</h2>
<p>如果<span class="math inline">\(X_i\)</span>是连续变量，可将<span class="math inline">\(p(X_i|Y)\)</span>建模为高斯分布。</p>
<p>NB是线性分类器（线性分类器是针对二分类，正类/负类由一个超平面分隔）</p>
<h1 id="logistic-regression">Logistic Regression</h1>
<p>正则化：<span class="math inline">\(-\lambda\|W\|^2\)</span></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>numpy</title>
    <url>/2019/10/03/numpy/</url>
    <content><![CDATA[<p>ndarray的<code>data</code>在内存中是连续存储的，通过<code>strides</code>属性来将索引映射到存储位置。<code>strides</code>是一个长度为<code>ndim</code>的tuple，表示相应轴上前进一个单位对应内存位置上增加的字节数。如果用<span class="math inline">\((s_1,\dots,s_n)\)</span>表示，索引用<span class="math inline">\(i_1,\dots,i_n\)</span>表示，那么对应的内存字节位置为<span class="math inline">\(\sum_{k=1}^ni_ks_k\)</span>。</p>
<p>有的操作只需要改变<code>strides</code>，引用的还是原来的<code>data</code>，这样的数组称为view。</p>
<p><code>np.full</code>：用任意常数构成数组</p>
<p><code>np.logspace</code>：和<code>linspace</code>类似，只不过是作为指数。</p>
<p><code>numpy.ones_like</code>等函数： 以另一个数组为参数，使得生成的数组有同样的shape和dtype。</p>
<p>通过切片得到的数组是view，因此改变这个数组会改变原数组。如果想要独立的数组，用copy。</p>
<p>fancy indexing：可以用整形数组和列表来作为索引。</p>
<p>还可以用bool数组作为索引，选中为<code>True</code>的位置。</p>
<p>通过fancy indexing和bool数组方式得到的是独立的数组，而不是view。但是可以通过这两种方式来改变数组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fancy indexing</span></span><br><span class="line">In [<span class="number">99</span>]: A = np.arange(<span class="number">10</span>)</span><br><span class="line">In [<span class="number">100</span>]: indices = [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>]</span><br><span class="line">In [<span class="number">101</span>]: B = A[indices]</span><br><span class="line">In [<span class="number">102</span>]: B[<span class="number">0</span>] = -<span class="number">1</span> <span class="comment"># this does not affect A</span></span><br><span class="line">In [<span class="number">103</span>]: A</span><br><span class="line">Out[<span class="number">103</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line">In [<span class="number">104</span>]: A[indices] = -<span class="number">1</span> <span class="comment"># this alters A</span></span><br><span class="line">In [<span class="number">105</span>]: A</span><br><span class="line">Out[<span class="number">105</span>]: array([ <span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>, <span class="number">3</span>, -<span class="number">1</span>, <span class="number">5</span>, -<span class="number">1</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Boolean-valued indexing</span></span><br><span class="line">In [<span class="number">106</span>]: A = np.arange(<span class="number">10</span>)</span><br><span class="line">In [<span class="number">107</span>]: B = A[A &gt; <span class="number">5</span>]</span><br><span class="line">In [<span class="number">108</span>]: B[<span class="number">0</span>] = -<span class="number">1</span> <span class="comment"># this does not affect A</span></span><br><span class="line">In [<span class="number">109</span>]: A</span><br><span class="line">Out[<span class="number">109</span>]: array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line">In [<span class="number">110</span>]: A[A &gt; <span class="number">5</span>] = -<span class="number">1</span> <span class="comment"># this alters A</span></span><br><span class="line">In [<span class="number">111</span>]: A</span><br><span class="line">Out[<span class="number">111</span>]: array([ <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p><code>reshape</code>创建view。</p>
<p><code>ravel</code>将数组展开成一维，创建view。</p>
<p><code>flatten</code>同样得到一维数组，但是是原数组的copy。</p>
<p>np.newaxis填充一个长度为1的轴。</p>
<h1 id="broadcast">broadcast</h1>
<p>两个数组如果维度不同，则维度较少的那个数组从左边开始填充长度为1的轴。之后两个数组相应轴比较，如果长度相等或者有一个长度为1，则能够应用broadcast。</p>
]]></content>
      <tags>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>test</title>
    <url>/2021/04/03/test/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>三维旋转</title>
    <url>/2019/08/10/%E4%B8%89%E7%BB%B4%E6%97%8B%E8%BD%AC/</url>
    <content><![CDATA[<h1 id="旋转三维向量">旋转三维向量</h1>
<p><img src="/images/3D-rotation.png" alt="对应关系" /> 图中<span class="math inline">\(\mathbf{u}\)</span>为单位向量，表示转轴。将<span class="math inline">\(\mathbf{x}\)</span>绕<span class="math inline">\(\mathbf{u}\)</span>逆时针旋转角度<span class="math inline">\(\phi\)</span>得到<span class="math inline">\(\mathbf{x}&#39;\)</span>。可将<span class="math inline">\(\mathbf{x}\)</span>分解为沿转轴的分量<span class="math inline">\(\mathbf{x}_{\parallel}\)</span>和垂直转轴的分量<span class="math inline">\(\mathbf{x}_{\perp}\)</span>。<span class="math inline">\(\mathbf{x}_{\parallel}\)</span>在转动时不变，<span class="math inline">\(\mathbf{x}_{\perp}\)</span>在平面上旋转角度<span class="math inline">\(\phi\)</span>得到<span class="math inline">\(\mathbf{x}_{\perp}&#39;\)</span>，可得 <span class="math display">\[
\mathbf{x}&#39;=\mathbf{x}_{\parallel}+\mathbf{x}_{\perp}\cos\phi+(\mathbf{u}\times\mathbf{x})\sin\phi
\label{3d-rotation}\tag{1}
\]</span></p>
<h1 id="旋转群">旋转群</h1>
<p>旋转保持：</p>
<ol type="1">
<li>向量长度</li>
<li>两向量的内积</li>
<li>相对方向 <span class="math inline">\(\mathbf{u}\times \mathbf{v}=\mathbf{w}\Longleftrightarrow r(\mathbf{u})\times r(\mathbf{v})=r(\mathbf{w})\)</span></li>
</ol>
<p>1,2是等价的。1-&gt;2可由<span class="math inline">\(\|r(\mathbf{u-v})\|=\|\mathbf{u-v}\|\)</span>得到，2-&gt;1可由<span class="math inline">\(r(\mathbf{u})\cdot r(\mathbf{u})=\mathbf{u}\cdot \mathbf{u}\)</span>得到。</p>
<p>因此可定义旋转群： <span class="math display">\[
SO(3):\{\mathbb{R}^3\to\mathbb{R}^3\mid\forall \mathbf{v},\mathbf{w}\in\mathbb{R}^3, \|r(\mathbf{v})\|=\|\mathbf{v}\|,r(\mathbf{v})\times r(\mathbf{w})=r(\mathbf{v}\times\mathbf{w})\}
\]</span></p>
<h1 id="旋转矩阵">旋转矩阵</h1>
<p>算符<span class="math inline">\(r\)</span>是线性的，可用矩阵<span class="math inline">\(R\)</span>表示， <span class="math display">\[
r(\mathbf{v})=\mathbf{Rv}
\]</span> 由 <span class="math display">\[
(\mathbf{Rv})^\top(\mathbf{Rv})=\mathbf{v}^\top\mathbf{R}^\top\mathbf{R}\mathbf{v}=\mathbf{v}^\top\mathbf{v}
\]</span> 可得： <span class="math display">\[
\mathbf{R}^\top\mathbf{R}=I
\]</span> 即旋转矩阵是正交矩阵。</p>
<p>由旋转性质3，对于向量<span class="math inline">\(\mathbf{u},\mathbf{v},\mathbf{w}\)</span>组成的六面体，旋转前后的有向体积应该相等，即 <span class="math display">\[
\begin{vmatrix}
Ru &amp; Rv &amp; Rw
\end{vmatrix}=\det(R)
\begin{vmatrix}
u &amp; v &amp; w
\end{vmatrix}=
\begin{vmatrix}
u &amp; v &amp; w
\end{vmatrix}
\]</span> 得<span class="math inline">\(\det(R)=1\)</span>。</p>
<p>这就构成了<span class="math inline">\(SO(3)\)</span>群(Special Orthogonal group)，其中的special就是指<span class="math inline">\(\det(R)=1\)</span>。</p>
<h2 id="指数映射">指数映射</h2>
<p><span class="math display">\[
\frac{d}{dt}(R^TR)=\dot{R}^TR+R^T\dot{R}=0
\]</span></p>
<p>得： <span class="math display">\[
R^T\dot{R}=-(R^T\dot{R})^T
\]</span> 即<span class="math inline">\(R^T\dot{R}\)</span>是反对称矩阵。这些反对称矩阵集合用<span class="math inline">\(\mathfrak{so}(3)\)</span>表示，称为<span class="math inline">\(SO(3)\)</span>的李代数。</p>
<p>反对称矩阵可以写成<span class="math inline">\([\omega]_{\times}\)</span>的形式，即 <span class="math display">\[
R^T\dot{R}=[\omega]_{\times}
\]</span> 得到： <span class="math display">\[
\dot{R}=R[\omega]_{\times}
\]</span> 当<span class="math inline">\(R=I\)</span>时，<span class="math inline">\(\dot{R}=[\omega]_{\times}\)</span>，即李代数是在幺元处的切空间。</p>
<p>如果<span class="math inline">\(\omega\)</span>为常数，上述方程解得： <span class="math display">\[
R(t)=R(0)e^{[\omega]_{\times}t}
\]</span> 这称为指数映射： <span class="math display">\[
\exp: \mathfrak{so}(3)\to SO(3);[\phi]_{\times}\mapsto \exp([\phi]_{\times})=e^{[\phi]_{\times}}
\]</span> 还可以定义"大写的"指数映射： <span class="math display">\[
\text{Exp}: \mathbb{R}^3\to SO(3);\phi\mapsto\text{Exp}(\phi)=e^{[\phi]_{\times}}
\]</span> 如果绕转轴<span class="math inline">\(\mathbf{u}\)</span>转了角度<span class="math inline">\(\phi\)</span>，那么旋转矩阵： <span class="math display">\[
\mathbf{R}=e^{\phi[\mathbf{u}]_{\times}}
\]</span> 上式按泰勒展开后得： <span class="math display">\[
\mathbf{R}=\mathbf{I}+\sin\phi[\mathbf{u}]_{\times}+(1-\cos\phi)[\mathbf{u}]_{\times}^2
\]</span> 这就是Rodrigues旋转公式。推导过程用到了 <span class="math display">\[
[\mathbf{a}]_{\times}^2=\mathbf{a}\mathbf{a}^\top-\mathbf{a}^\top\mathbf{aI}
\]</span> 根据这个式子，又可写成： <span class="math display">\[
\mathbf{R}=\cos\phi\mathbf{I}+\sin\phi[\mathbf{u}]_{\times}+(1-\cos\phi)\mathbf{u}\mathbf{u}^\top
\]</span></p>
<h2 id="对数映射">对数映射</h2>
<p>从<span class="math inline">\(\mathbf{R}\)</span>得到<span class="math inline">\(\phi\)</span>和<span class="math inline">\(\mathbf{u}\)</span> <span class="math display">\[
\phi=\arccos\left(\frac{tr(\mathbf{R})-1}{2}\right)\\
\mathbf{u}=\frac{(\mathbf{R}-\mathbf{R}^T)^\vee}{2\sin\phi}
\]</span> 其中<span class="math inline">\(\bullet ^\vee\)</span>是<span class="math inline">\([\bullet]_{\times}\)</span>的逆，即<span class="math inline">\(([\mathbf{v}_{\times}]^\vee)=\mathbf{v}\)</span>.</p>
<h2 id="旋转作用">旋转作用</h2>
<p>将<span class="math inline">\(\mathbf{R}=\text{Exp}(\mathbf{u}\phi)\)</span>作用在向量<span class="math inline">\(\mathbf{x}\)</span>上，得到： <span class="math display">\[
\begin{aligned}
\mathbf{x}&#39;&amp;=\mathbf{R}\mathbf{x}\\
&amp;=(\mathbf{I}+\sin\phi[\mathbf{u}]_{\times}+(1-\cos\phi)[\mathbf{u}]_{\times}^2)\mathbf{x}\\
&amp;=\mathbf{x}_{\parallel}+\mathbf{x}_{\perp}\cos\phi+(\mathbf{u}\times\mathbf{x})\sin\phi
\end{aligned}
\]</span> 与式<span class="math inline">\((\ref{3d-rotation})\)</span>一致。</p>
<h1 id="四元数">四元数</h1>
<p>旋转公式为： <span class="math display">\[
\mathbf{x}&#39;=\mathbf{q}\otimes\mathbf{x}\otimes\mathbf{q}^*
\label{quat-rotation}\tag{2}
\]</span> 由于 <span class="math display">\[
\|\mathbf{x}&#39;\|=\|\mathbf{q}\|^2\|\mathbf{x}\|=\|\mathbf{x}\|
\]</span> 因此<span class="math inline">\(\|\mathbf{q}\|^2=1\)</span>，即<span class="math inline">\(\mathbf{q}\)</span>是单位四元数： <span class="math display">\[
\mathbf{q}^*\otimes\mathbf{q}=1=\mathbf{q}\otimes\mathbf{q}^*
\]</span> 这与<span class="math inline">\(R^TR=I=RR^T\)</span>的条件类似。</p>
<p>还可以看到，自动保持了相对方向： <span class="math display">\[
\begin{aligned}
r(v)\times r(w)&amp;=(q\otimes v\otimes q^*)\times(q\otimes w\otimes q^*)\\
&amp;=\frac{1}{2}\left((q\otimes v\otimes q^*)\otimes(q\otimes w\otimes q^*)-(q\otimes w\otimes q^*)\otimes(q\otimes v\otimes q^*)\right)\\
&amp;=\frac{1}{2}(q\otimes v\otimes w\otimes q^*-q\otimes w\otimes v\otimes q^*)\\
&amp;=\frac{1}{2}(q\otimes(v\otimes w-w\otimes v)\otimes q^*)\\
&amp;=q\otimes(v\times w)\otimes q^*\\
&amp;=r(v\times w)
\end{aligned}
\]</span></p>
<h2 id="指数映射-1">指数映射</h2>
<p><span class="math display">\[
\frac{d(q^*\otimes q)}{dt}=\dot{q}^*\otimes q+q^*\otimes\dot{q}=0
\]</span></p>
<p>得： <span class="math display">\[
q^*\otimes\dot{q}=-(\dot{q}^*\otimes q)=-(q^*\otimes\dot{q})^*
\]</span> 即<span class="math inline">\(q^*\otimes\dot{q}\)</span>是虚四元数。令： <span class="math display">\[
q^*\otimes\dot{q}=\Omega
\]</span> 得到： <span class="math display">\[
\dot{q}=q\otimes\Omega
\]</span> 当<span class="math inline">\(q=1\)</span>时，<span class="math inline">\(\dot{q}=\Omega\)</span>，可见虚四元数构成了单位四元数球<span class="math inline">\(S^3\)</span>的切空间。</p>
<p>如果<span class="math inline">\(\Omega\)</span>为常数，上式解得<span class="math inline">\(q(t)=q(0)\otimes e^{\Omega t}\)</span>，这就引出了指数映射。</p>
<p>如果绕转轴<span class="math inline">\(\mathbf{u}\)</span>转了角度<span class="math inline">\(\phi\)</span>，定义“大写的”指数映射： <span class="math display">\[
\mathbf{q}\triangleq \text{Exp}(\phi\mathbf{u})=e^{\phi\mathbf{u}/2}=\cos\frac{\phi}{2}+\mathbf{u}\sin\frac{\phi}{2}
\label{quat-form}\tag{3}
\]</span></p>
<h2 id="旋转作用-1">旋转作用</h2>
<p>将式<span class="math inline">\((\ref{quat-form})\)</span>代入式<span class="math inline">\((\ref{quat-rotation})\)</span>， 推导可得式<span class="math inline">\((\ref{3d-rotation})\)</span>，这就验证了正确性。</p>
<p>在证明中有一步<span class="math inline">\(\mathbf{u}\otimes\mathbf{x}\otimes\mathbf{u}=\mathbf{x}(\mathbf{u}^T\mathbf{u})-2\mathbf{u}(\mathbf{u}^T\mathbf{x})\)</span>用到了<span class="math inline">\((a\times b)\times c=-a(c\cdot b)+b(c\cdot a)\)</span></p>
<h1 id="四元数到旋转矩阵的转换">四元数到旋转矩阵的转换</h1>
<p>由 <span class="math display">\[
\mathbf{q}\otimes\mathbf{x}\otimes\mathbf{q}^*=[\mathbf{q}^*]_R[\mathbf{q}]_L
\begin{bmatrix}
0\\
\mathbf{x}
\end{bmatrix}=
\begin{bmatrix}
0\\
\mathbf{\mathbf{R}x}
\end{bmatrix}
\]</span> 可以得到： <span class="math display">\[
\mathbf{R}=(q_w^2-\mathbf{q}_v^\top\mathbf{q}_v)\mathbf{I}+2\mathbf{q}_v\mathbf{q}_v^\top+2q_w[\mathbf{q}_v]_\times
\]</span></p>
<h1 id="旋转合成">旋转合成</h1>
<p>四元数和旋转矩阵的合成顺序一样： <span class="math display">\[
\mathbf{R}\{\mathbf{q}_2\otimes\mathbf{q}_1\}=\mathbf{R}\{\mathbf{q}_2\}\mathbf{R}\{\mathbf{q}_1\}
\]</span> 这是因为<span class="math inline">\(\mathbf{q}_2\otimes\mathbf{q}_1\)</span>作用于<span class="math inline">\(\mathbf{x}\)</span>时，是<span class="math inline">\(\mathbf{q}_1\)</span>先作用： <span class="math display">\[
\mathbf{q}_2\otimes\mathbf{q}_1\otimes\mathbf{x}\otimes(\mathbf{q}_2\otimes\mathbf{q}_1)^*=\mathbf{q}_2\otimes(\mathbf{q}_1\otimes\mathbf{x}\otimes\mathbf{q}_1^*)\otimes\mathbf{q}_2^*
\]</span></p>
<h1 id="参考资料">参考资料</h1>
<p><a href="https://arxiv.org/pdf/1711.02508.pdf">Quaternion kinematics for the error-state Kalman filter</a></p>
]]></content>
      <tags>
        <tag>四元数</tag>
      </tags>
  </entry>
  <entry>
    <title>信息论-熵</title>
    <url>/2019/10/14/%E4%BF%A1%E6%81%AF%E8%AE%BA-%E7%86%B5/</url>
    <content><![CDATA[<p>熵： <span class="math display">\[
H(X)=-\sum_{x\in\mathcal{X}}    p(x)\log p(x)
\]</span></p>
<p>联合熵： <span class="math display">\[
H(X,Y)=-\sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}p(x,y)\log p(x,y)
\]</span> 条件熵：给定条件变量<span class="math inline">\(X\)</span>取值<span class="math inline">\(x\)</span>，可以求<span class="math inline">\(H(Y|X=x)\)</span>，然后对<span class="math inline">\(X\)</span>求期望 <span class="math display">\[
\begin{align}
H(Y|X)&amp;=\sum_{x\in\mathcal{X}}p(x)H(Y|X=x)\\
&amp;=-\sum_{x\in\mathcal{X}}p(x)\sum_{y\in\mathcal{Y}}p(y|x)\log p(y|x)\\
&amp;=-\sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}p(x,y)\log p(y|x)
\end{align}
\]</span> <span class="math inline">\(H(X,Y)=H(Y|X)+H(X)\)</span></p>
<p>证明： <span class="math display">\[
\begin{align}
H(X,Y)&amp;=-\sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}p(x,y)\log p(x,y)\\
&amp;=-\sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}p(x,y)\log \Big(p(y|x)p(x)\Big)\\
&amp;=-\sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}p(x,y)\Big(\log p(y|x)+\log p(x)\Big)\\
&amp;=H(Y|X)-\sum_{x\in\mathcal{X}}\log p(x)\sum_{y\in\mathcal{Y}}p(x,y)\\
&amp;=H(Y|X)-\sum_{x\in\mathcal{X}}p(x)\log p(x)\\
&amp;=H(Y|X)+H(X)
\end{align}
\]</span> 可进一步推广为链式法则： <span class="math display">\[
H(X_1,X_2,\dots,X_n)=\sum_{i=1}^nH(X_i|X_{i-1},\dots,X_1)
\]</span></p>
<p>相对熵（也叫Kullback–Leibler距离 ）度量两个随机分布之间的距离：对于概率分布<span class="math inline">\(p(x),q(x)\)</span> <span class="math display">\[
D(p\|q)=\sum_{x\in\mathcal{X}}p(x)\frac{p(x)}{q(x)}
\]</span> 相对熵总是非负的，当且仅当<span class="math inline">\(p=q\)</span>时为0（由Jensen不等式证明）。但是相对熵并不对称，也不满足三角不等式，所以不是metric。</p>
<p>互信息：是联合分布和乘积分布<span class="math inline">\(p(x)p(y)\)</span>的相对熵： <span class="math display">\[
\begin{align}
I(X;Y)&amp;=\sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}p(x,y)\log\frac{p(x,y)}{p(x)p(y)}\\
&amp;=D(p(x,y)\|p(x)p(y))
\end{align}
\]</span></p>
<p><span class="math display">\[
\begin{align}
I(X;Y)&amp;=\sum_{x,y}p(x,y)\log\frac{p(x,y)}{p(x)p(y)}\\
&amp;=\sum_{x,y}p(x,y)\log\frac{p(x|y)}{p(x)}\\
&amp;=-\sum_{x,y}p(x,y)\log p(x)+\sum_{x,y}p(x,y)\log p(x|y)\\
&amp;=H(X)-H(X|Y)
\end{align}
\]</span></p>
<p>因此互信息是由<span class="math inline">\(Y\)</span>的知识造成的<span class="math inline">\(X\)</span>的不确定度的缩减。由于互信息是相对熵，因此非负，当且仅当<span class="math inline">\(p(x,y)=p(x)p(y)\)</span>，即<span class="math inline">\(X,Y\)</span>独立时为0。</p>
<p>由<span class="math inline">\(I(X;Y)=I(Y;X)=H(Y)-H(Y|X)\)</span>，<span class="math inline">\(X,Y\)</span>对彼此的提供的信息量是一样的，这也许就是<strong>mutual</strong>的含义。</p>
<p>由之前推导还可得： <span class="math display">\[
I(X;Y)=H(X)+H(Y)-H(X,Y)\\
I(X;X)=H(X)-H(X|X)=H(X)
\]</span></p>
]]></content>
  </entry>
  <entry>
    <title>决策树</title>
    <url>/2019/10/14/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h1 id="选择划分属性">选择划分属性</h1>
<h2 id="information-gain">information gain</h2>
<p>就是信息论中的互信息： <span class="math display">\[
H(Y)-H(Y|a)
\]</span> 其中<span class="math inline">\(a\)</span>为属性。</p>
<p>如果<span class="math inline">\(a\)</span>取值较多，那么<span class="math inline">\(H(Y|a)\)</span>可能会偏小。极端的例子为<span class="math inline">\(a\)</span>为样例编号，那么<span class="math inline">\(H(Y|a)=0\)</span>。</p>
<p>C4.5中使用的是gain ratio，也就是： <span class="math display">\[
\frac{H(Y)-H(Y|a)}{H(a)}
\]</span> 其中<span class="math inline">\(H(a)\)</span>为数据集关于属性<span class="math inline">\(a\)</span>的熵。<span class="math inline">\(a\)</span>取值越多，值可能越分散，因而<span class="math inline">\(H(a)\)</span>可能越大。</p>
<p>C4.5先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。</p>
<h2 id="gini-index">Gini index</h2>
<p><span class="math display">\[
\text{Gini}(D)=1-\sum_{k=1}^{|\mathcal{Y}|}p_k^2
\]</span></p>
<p>其中<span class="math inline">\(p_k\)</span>表示第<span class="math inline">\(k\)</span>类的概率。</p>
<p>基尼指数反映了从数据集<span class="math inline">\(D\)</span>中随机抽取两个样本，其类别标记不同的概率。因此越小数据集的纯度越高。</p>
<p>属性<span class="math inline">\(a\)</span>的基尼指数： <span class="math display">\[
\text{Gini}(D,a)=\sum_{v=1}^V\frac{|D^v|}{|D|}\text{Gini}(D^v)
\]</span> 其中<span class="math inline">\(D^v\)</span>为属性<span class="math inline">\(a\)</span>的取值为第<span class="math inline">\(v\)</span>个值的数据。</p>
<p>那么选取的属性为： <span class="math display">\[
a_* = \text{argmin}_{a\in A}\text{Gini}(D,a)
\]</span></p>
<h1 id="剪枝">剪枝</h1>
<p>剪枝的基本策略有“预剪枝”和“后剪枝”。</p>
<p>预剪枝：在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来泛化性能提升，则停止划分并将当前结点标记为叶节点。</p>
<p>后剪枝：先从训练集生成一颗完整的决策树，然后自底向上对非叶结点进行考察，若将该结点对应的子树替换为叶结点能提升泛化性能，则替换。</p>
<p>预剪枝使得决策树的很多分支没有展开，降低了过拟合的风险，但这是基于贪心的策略（后续划分可能导致性能提高），带来了欠拟合的风险。</p>
<h1 id="连续属性">连续属性</h1>
<p>假设<span class="math inline">\(a\)</span>在<span class="math inline">\(D\)</span>中出现了<span class="math inline">\(n\)</span>个不同的取值，将这些值从小到大排序，记为<span class="math inline">\(\{a^1,a2,\dots,a^n\}\)</span>。基于划分点<span class="math inline">\(t\)</span>可分为不大于和大于的集合。<span class="math inline">\(t\)</span>的取值集合为： <span class="math display">\[
T_a=\{\frac{a^i+a^{i+1}}{2}|1\le i\le n-1\}
\]</span> 若当前结点划分属性为连续属性，该属性还可以作为其后代结点的划分属性。</p>
<h1 id="缺失值处理">缺失值处理</h1>
<p>两个问题：</p>
<ol type="1">
<li>如何在属性值缺失的情况下选择划分属性？</li>
<li>给定划分属性，若某样本在该属性上的值缺失，如果将样本划分到子节点？</li>
</ol>
<p>用<span class="math inline">\(\tilde{D}\)</span>表示<span class="math inline">\(D\)</span>中在属性<span class="math inline">\(a\)</span>上没有缺失值的样本子集。</p>
<p>对于问题1，可以在<span class="math inline">\(\tilde{D}\)</span>中计算指标（比如信息增益），然后乘以<span class="math inline">\(\tilde{D}\)</span>相对于<span class="math inline">\(D\)</span>的权重（由于问题2，样本的权重会变，所以并不只是样本的比例），表示对指标的置信程度。</p>
<p>对于问题2，如果样本<span class="math inline">\(x\)</span>在<span class="math inline">\(a\)</span>上的值已知，则划入对应的子节点。如果取值缺失，则将<span class="math inline">\(x\)</span>同时划入所有子节点，且样本权重按子节点的比例调整。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>坐标系转换</title>
    <url>/2019/08/25/%E5%9D%90%E6%A0%87%E7%B3%BB%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<h1 id="方向余弦矩阵dcm">方向余弦矩阵（DCM）</h1>
<p><span class="math inline">\(\mathbf{r}_A,\mathbf{r}_B\)</span>分别为向量<span class="math inline">\(\mathbf{r}\)</span>在坐标系<span class="math inline">\(A，B\)</span>中的坐标，由 <span class="math display">\[
\mathbf{r}= \begin{pmatrix}\mathbf{i}_B &amp; \mathbf{j}_B &amp; \mathbf{k}_B
\end{pmatrix}\mathbf{r}_B=\begin{pmatrix}\mathbf{i}_A &amp; \mathbf{j}_A &amp; \mathbf{k}_A
\end{pmatrix}\mathbf{r}_A
\]</span></p>
<p>得： <span class="math display">\[
\begin{aligned}
\mathbf{r}_B&amp;=\begin{pmatrix}\mathbf{i}_B^\intercal\\
\mathbf{j}_B^\intercal\\
\mathbf{k}_B^\intercal
\end{pmatrix}\begin{pmatrix}\mathbf{i}_A &amp; \mathbf{j}_A &amp; \mathbf{k}_A
\end{pmatrix}\mathbf{r}_A\\
&amp;\triangleq R_{BA}\mathbf{r}_A
\end{aligned}
\]</span> <span class="math inline">\(R_{BA}\)</span>表示从<span class="math inline">\(A\)</span>到<span class="math inline">\(B\)</span>的坐标转换矩阵。</p>
<p>由<span class="math inline">\(R_{BA}\)</span>的定义还可得基变换： <span class="math display">\[
\begin{pmatrix}\mathbf{i}_A &amp; \mathbf{j}_A &amp; \mathbf{k}_A
\end{pmatrix}=\begin{pmatrix}\mathbf{i}_B &amp; \mathbf{j}_B &amp; \mathbf{k}_B
\end{pmatrix}R_{BA}
\]</span></p>
<h1 id="欧拉角">欧拉角</h1>
<p>intrinsic rotation是指绕当前坐标系（而不是某个固定坐标系）的轴转动。</p>
<p><span class="math inline">\(A\)</span>绕某轴逆时针旋转<span class="math inline">\(\theta\)</span>，得到<span class="math inline">\(B\)</span>。对于<span class="math inline">\(R_{BA}\)</span>，根据定义得出如下结果<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>：</p>
<p>绕<span class="math inline">\(X\)</span>轴旋转 <span class="math display">\[
R_x=
\begin{bmatrix}
  1 &amp; 0 &amp; 0 \\
   0 &amp; c_\theta &amp; s_\theta \\  
    0 &amp; -s_\theta &amp; c_\theta 
\end{bmatrix}
\]</span> 绕<span class="math inline">\(Y\)</span>轴旋转 <span class="math display">\[
R_y=
\begin{bmatrix} 
    c_\theta &amp; 0 &amp; -s_\theta \\  
    0 &amp; 1 &amp; 0\\
    s_\theta &amp; 0 &amp; c_\theta  
\end{bmatrix}
\]</span> 绕<span class="math inline">\(Z\)</span>轴旋转 <span class="math display">\[
R_z=
\begin{bmatrix} 
    c_\theta &amp; s_\theta &amp; 0\\  
    -s_\theta &amp; c_\theta &amp; 0\\  
    0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span> 如果按<span class="math inline">\(Z\rightarrow Y\rightarrow X\)</span>的顺序转动， <span class="math display">\[
R_{BA}=R_xR_yR_z=\begin{bmatrix}       
    c_yc_z &amp; c_ys_z &amp; -s_y \\
    s_xs_yc_z-c_xs_z &amp; s_xs_ys_z+c_xc_z &amp; s_xc_y \\
    c_xs_yc_z+s_xs_z &amp; c_xs_ys_z-s_xc_z &amp; c_xc_y
\end{bmatrix}
\]</span> 可得欧拉角和DCM的转换关系： <span class="math display">\[
\text{tan}(\theta_z)=\frac {R_{12}} {R_{11}}\\
\text{sin}(\theta_y)=-R_{13}\\
\text{tan}(\theta_x)=\frac {R_{23}} {R_{33}}
\]</span> 若是小角度转动， <span class="math display">\[
\begin{equation}
R=\begin{bmatrix}
1  &amp; \theta_z &amp; -\theta_y\\
-\theta_z &amp; 1 &amp; \theta_x\\
\theta_y &amp; -\theta_x &amp; 1
\end{bmatrix}=I-[\theta]_\times
\end{equation}
\]</span> 可见小角度转动与转动顺序无关（即只与绕XYZ各轴转过的角度有关。如果只有俩轴，比如Z-&gt;X-&gt;Z，那么未出现的轴角度为0，出现两次的轴的角度相加）。</p>
<h2 id="extrinsic-rotation">Extrinsic rotation</h2>
<p>设固定坐标系为<span class="math inline">\(A\)</span>。坐标系<span class="math inline">\(B\)</span>绕<span class="math inline">\(A\)</span>的<span class="math inline">\(\mathbf{u}\)</span>轴转动角度<span class="math inline">\(\phi\)</span>，这个转动用<span class="math inline">\(R_{\phi \mathbf{u}}\)</span>表示，得坐标系<span class="math inline">\(C\)</span>。求<span class="math inline">\(R_{CA}\)</span>。</p>
<p>首先 <span class="math display">\[
R_{CA}=R_{BD}
\]</span> 其中<span class="math inline">\(D\)</span>为<span class="math inline">\(A\)</span>绕<span class="math inline">\(\mathbf{u}\)</span>轴转动角度<span class="math inline">\(-\phi\)</span>得到。这个结论对于二维转动很直观，对于三维其实也容易看出。按定义，只要证明两对坐标系的基的内积相等即可。把基分解到平行于转轴和垂直于转轴。平行部分的内积显然不变，垂直部分由二维情况可知也不变，且平行于垂直部分内积为0。因此得证。 <span class="math display">\[
R_{BD}=R_{BA}R_{AD}=R_{BA}R_{DA}^{-1}=R_{BA}R_{-\phi \mathbf{u}}^{-1}=R_{BA}R_{\phi \mathbf{u}}
\]</span> 因此得到结论，绕固定坐标系的轴转动，<span class="math inline">\(R\)</span>是乘在右边的。</p>
<h1 id="四元数">四元数</h1>
<p><span class="math display">\[
\mathbf{x}_G=\mathbf{q}_{GL}\otimes \mathbf{x}_L\otimes\mathbf{q}^*_{GL}
\]</span></p>
<p>其中G表示global，或者n系；L表示local，或者b系。</p>
<p>这样定义是为了和旋转三维向量的公式形式保持一致。</p>
<h1 id="运动方程">运动方程</h1>
<h2 id="四元数-1">四元数</h2>
<p>如果是在L系中表达扰动（即上述的intrinsic rotation）， <span class="math display">\[
q(t+\Delta t)=q(t)\otimes\Delta q_L=q(t)\otimes\text{Exp}(\Delta\phi_L)
\]</span> <span class="math display">\[
\begin{aligned}
\dot{q}&amp;\triangleq \lim_{\Delta t\to 0}\frac{q(t+\Delta t)-q(t)}{\Delta t}\\
&amp;=\lim_{\Delta t\to 0}\frac{q\otimes\Delta q_L-q}{\Delta t}\\
&amp;=\lim_{\Delta t\to 0}\frac{q\otimes\left(\begin{bmatrix}1\\\Delta\phi_L/2\end{bmatrix}-\begin{bmatrix}1\\0\end{bmatrix}\right)}{\Delta t}\\
&amp;=\lim_{\Delta t\to 0}\frac{q\otimes\begin{bmatrix}0\\\Delta\phi_L/2\end{bmatrix}}{\Delta t}\\
&amp;=\frac{1}{2}q\otimes \omega_L
\end{aligned}
\]</span></p>
<p>其中<span class="math inline">\(\text{Exp}(\Delta\phi_L)\)</span>用了小角度近似。</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><span class="math inline">\(s_\theta\)</span>放置位置记忆方法：放在转动轴的上一列（循环）。<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <tags>
        <tag>四元数</tag>
      </tags>
  </entry>
  <entry>
    <title>平面最近点对问题</title>
    <url>/2019/10/13/%E5%B9%B3%E9%9D%A2%E6%9C%80%E8%BF%91%E7%82%B9%E5%AF%B9%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="分治法">分治法</h1>
<p>竖直线<span class="math inline">\(l\)</span>将点集平分为两部分，<span class="math inline">\(d_L,d_R\)</span> 分别表示左右两边的点集的最小距离，令<span class="math inline">\(\delta = \min(d_L,d_R)\)</span>。为了使一个点在左，一个在右的距离小于<span class="math inline">\(\delta\)</span>，只需在<span class="math inline">\(l\)</span>两边宽度为<span class="math inline">\(\delta\)</span>的条带中找。如下图所示</p>
<figure>
<img src="/images/closest-pair-1.png" alt="closest-pair-1" /><figcaption aria-hidden="true">closest-pair-1</figcaption>
</figure>
<p>同时两个点在竖直方向上距离不能超过<span class="math inline">\(\delta\)</span>，因此只需在<span class="math inline">\(\delta\times 2\delta\)</span>的框内找。考虑到左边的<span class="math inline">\(\delta\times \delta\)</span>的框内两点间的距离不能超过<span class="math inline">\(\delta\)</span>，因此最多只能有4个点。右边同理。如下图所示</p>
<figure>
<img src="/images/closest-pair-2.png" alt="closest-pair-2" /><figcaption aria-hidden="true">closest-pair-2</figcaption>
</figure>
<p>因此在按y坐标排序的点集中，只需计算随后的7个点。这样计算由分别在左右的点构成的点对的时间为<span class="math inline">\(O(n)\)</span>，整个算法的复杂度因此为<span class="math inline">\(O(n\log n)\)</span>。</p>
<h1 id="参考资料">参考资料</h1>
<ol type="1">
<li>算法导论 第三版</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title>四元数</title>
    <url>/2019/08/17/%E5%9B%9B%E5%85%83%E6%95%B0/</url>
    <content><![CDATA[<h1 id="定义">定义</h1>
<p><span class="math display">\[
Q = a+bi+cj+dk
\]</span> 其中<span class="math inline">\({i,j,k}\)</span>是虚数单元，满足： <span class="math display">\[
i^2=j^2=k^2=ijk=-1
\]</span> <span class="math inline">\(Q=a\)</span>称为实四元数，<span class="math inline">\(Q=bi+cj+dk\)</span>称为虚四元数。<br />
实部+虚部的表示方式有时不方便，只要遵循虚部的运算规则，就可以写成标量+向量的形式： <span class="math display">\[
Q=q_w+q_xi+q_yj+q_zk\quad \Leftrightarrow\quad Q=q_w+\mathbf{q}_v
\]</span> 下面将四元数<span class="math inline">\(Q\)</span>写成四维向量<span class="math inline">\(\mathbf{q}\)</span>的形式： <span class="math display">\[
\mathbf{q}\triangleq 
\begin{bmatrix}
q_w\\
\mathbf{q}_v
\end{bmatrix}=
\begin{bmatrix}
q_w\\
q_x\\
q_y\\
q_z
\end{bmatrix}
\]</span> 这样就可以用矩阵来进行有关四元数的运算。</p>
<h1 id="主要性质">主要性质</h1>
<h2 id="乘法">乘法</h2>
<p>四元数的乘法只要按定义来进行就行了，用标量和向量的形式来表示是比较方便的： <span class="math display">\[
\mathbf{p}\otimes\mathbf{q}=
\begin{bmatrix}
p_wq_w-\mathbf{p}_v^\top\mathbf{q}_v\\
p_w\mathbf{q}_v+q_w\mathbf{p}_v+\mathbf{p}_v\times\mathbf{q}_v
\end{bmatrix}
\]</span> 由于结果的向量部分有个叉积，而叉积不满足交换律，因此四元数乘法一般也不满足交换律，即： <span class="math display">\[
\mathbf{p}\otimes\mathbf{q}\neq\mathbf{q}\otimes\mathbf{p}
\]</span> 但是乘法满足结合律（暴力验证）： <span class="math display">\[
(\mathbf{p}\otimes\mathbf{q})\otimes\mathbf{r}=\mathbf{p}\otimes(\mathbf{q}\otimes\mathbf{r})
\]</span> 四元数乘法可以写成矩阵乘法的形式： <span class="math display">\[
\mathbf{q_1}\otimes\mathbf{q_2}=[\mathbf{q_1}]_L\mathbf{q_2}\\
\mathbf{q_1}\otimes\mathbf{q_2}=[\mathbf{q_2}]_R\mathbf{q_1}
\]</span> 其中 <span class="math display">\[
[\mathbf{q}]_L=q_w\mathbf{I}+
\begin{bmatrix}
0 &amp; -\mathbf{q}_v^\top\\
\mathbf{q}_v &amp; [\mathbf{q}_v]_{\times}
\end{bmatrix}
\]</span> <span class="math display">\[
[\mathbf{q}]_R=q_w\mathbf{I}+
\begin{bmatrix}
0 &amp; -\mathbf{q}_v^\top\\
\mathbf{q}_v &amp; -[\mathbf{q}_v]_{\times}
\end{bmatrix}
\]</span> 这里用到了反对称矩阵： <span class="math display">\[
[\mathbf{a}]_{\times}\triangleq 
\begin{bmatrix}
0 &amp; -a_z &amp; a_y\\
a_z &amp; 0 &amp; -a_x\\
-a_y &amp; a_x &amp;  0
\end{bmatrix}
\]</span> 这个矩阵和叉积有关： <span class="math display">\[
[\mathbf{a}]_{\times}\mathbf{b}=\mathbf{a}\times\mathbf{b}
\]</span> <span class="math display">\[
[\mathbf{q}]_L[\mathbf{q}]_L^T=[\mathbf{q}]_R[\mathbf{q}]_R^T=\|\mathbf{q}\|^2I
\]</span> 即如果<span class="math inline">\(\mathbf{q}\)</span>是单位四元数，那么这两个矩阵是正交矩阵。</p>
<p>由于 <span class="math display">\[
\begin{aligned}
\mathbf{q}\otimes\mathbf{x}\otimes\mathbf{p}&amp;=(\mathbf{q}\otimes\mathbf{x})\otimes\mathbf{p}=[\mathbf{p}]_R[\mathbf{q}]_L\mathbf{x}\\
&amp;=\mathbf{q}\otimes(\mathbf{x}\otimes\mathbf{p})=[\mathbf{q}]_L[\mathbf{p}]_R\mathbf{x}
\end{aligned}
\]</span></p>
<p>可见L,R矩阵满足交换律： <span class="math display">\[
[\mathbf{p}]_R[\mathbf{q}]_L=[\mathbf{q}]_L[\mathbf{p}]_R
\]</span></p>
<h2 id="identity">identity</h2>
<p>幺元<span class="math inline">\(\mathbf{q_1}\)</span>满足： <span class="math display">\[
\mathbf{q_1}\otimes\mathbf{q}=\mathbf{q}\otimes\mathbf{q_1}=\mathbf{q}
\]</span> 它就是实数1： <span class="math display">\[
\mathbf{q_1}=1=
\begin{bmatrix}
1\\
\mathbf{0}_v
\end{bmatrix}
\]</span></p>
<h2 id="共轭">共轭</h2>
<p>和复数类似，共轭定义为： <span class="math display">\[
\mathbf{q}^*\triangleq q_w-\mathbf{q}_v=
\begin{bmatrix}
q_w\\
-\mathbf{q}_v
\end{bmatrix}
\]</span> 满足： <span class="math display">\[
\mathbf{q}\otimes\mathbf{q}^*=\mathbf{q}^*\otimes\mathbf{q}=q_w^2+q_x^2+q_y^2+q_z^2
\]</span> <span class="math display">\[
(\mathbf{p}\otimes\mathbf{q})^*=\mathbf{q}^*\otimes\mathbf{p}^*
\]</span></p>
<h2 id="norm">norm</h2>
<p>范数定义为： <span class="math display">\[
\|\mathbf{q}\| \triangleq \sqrt{\mathbf{q}\otimes\mathbf{q}^*}=\sqrt{q_w^2+q_x^2+q_y^2+q_z^2}
\]</span> 满足： <span class="math display">\[
\|\mathbf{p}\otimes\mathbf{q}\|=\|\mathbf{p}\|\|\mathbf{q}\|
\]</span></p>
<h2 id="逆">逆</h2>
<p>逆定义为： <span class="math display">\[
\mathbf{q}\otimes\mathbf{q}^{-1}=\mathbf{q}^{-1}\otimes\mathbf{q}=\mathbf{q}_1
\]</span> 显然， <span class="math display">\[
\mathbf{q}^{-1}=\frac{\mathbf{q}^*}{\|\mathbf{q}\|^2}
\]</span></p>
<h2 id="单位四元数">单位四元数</h2>
<p>或者叫归一化的四元数定义为<span class="math inline">\(\|\mathbf{q}\|=1\)</span>，因此 <span class="math display">\[
\mathbf{q}^{-1}=\mathbf{q}^*
\]</span> 单位四元数可以写成： <span class="math display">\[
\mathbf{q}=
\begin{bmatrix}
\cos\theta\\
\mathbf{u}\sin\theta
\end{bmatrix}
\]</span> 其中<span class="math inline">\(\|\mathbf{u}\|=1\)</span>。</p>
<h1 id="附加性质">附加性质</h1>
<h2 id="虚四元数的乘法">虚四元数的乘法</h2>
<p><span class="math display">\[
\mathbf{q}_v\otimes\mathbf{q}_v=-\mathbf{q}_v^\top\mathbf{q}_v=-\|\mathbf{q}_v\|^2
\]</span> 对于单位虚四元数<span class="math inline">\(\|\mathbf{u}\|=1\)</span>，因此： <span class="math display">\[
\mathbf{u}\otimes \mathbf{u}=-1
\]</span> 与虚数<span class="math inline">\(i\cdot i=-1\)</span>类似。</p>
<h2 id="虚四元数的指数函数">虚四元数的指数函数</h2>
<p>与实数类似，根据级数展开来定义： <span class="math display">\[
e^{\mathbf{q}}\triangleq \sum_{0}^{\infty}\frac{1}{k!}\mathbf{q}^k
\]</span> 对于虚四元数<span class="math inline">\(\mathbf{v}=\mathbf{u}\theta\)</span>，其中<span class="math inline">\(\|\mathbf{u}\|=1\)</span>，有： <span class="math display">\[
e^{\mathbf{v}}=e^{\mathbf{u}\theta}=\cos\theta+\mathbf{u}\sin\theta=
\begin{bmatrix}
\cos\theta\\
\mathbf{u}\sin\theta
\end{bmatrix}
\]</span> 是虚数的欧拉公式的扩展。 注意<span class="math inline">\(\|e^{\mathbf{v}}\|=1\)</span>，因此虚四元数的指数函数为单位四元数。</p>
<h2 id="一般四元数的指数函数">一般四元数的指数函数</h2>
<p>由于当其中一个四元数为实数时，四元数乘法满足交换律，因此： <span class="math display">\[
e^{\mathbf{q}}=e^{q_w+\mathbf{q}_v}=e^{q_w}e^{\mathbf{q}_v}
\]</span></p>
<h2 id="单位四元数的对数">单位四元数的对数</h2>
<p>四元数的对数用指数来定义，如果<span class="math inline">\(\|\mathbf{q}\|=1\)</span>， <span class="math display">\[
\log \mathbf{q}=\log(\cos\theta+\mathbf{u}\sin\theta)=\log(e^{\mathbf{u}\theta})=\mathbf{u}\theta
\]</span></p>
<h2 id="一般四元数的对数">一般四元数的对数</h2>
<p><span class="math display">\[
\log\mathbf{q}=\log(\|\mathbf{q}\|\frac{\mathbf{q}}{\|\mathbf{q}\|})=\log\|\mathbf{q}\|+\mathbf{u}\theta
\]</span></p>
<h2 id="exponential-forms-of-the-type-mathbfqt">Exponential forms of the type <span class="math inline">\(\mathbf{q}^t\)</span></h2>
<p>对于<span class="math inline">\(t\in \mathbb{R}\)</span>， <span class="math display">\[
\mathbf{q}^t=\exp(\log(\mathbf{q}^t))=\exp(t\log(\mathbf{q}))
\]</span> 如果<span class="math inline">\(\|\mathbf{q}\|=1\)</span>，写成<span class="math inline">\(\mathbf{q}=\begin{bmatrix}\cos\theta, &amp; \mathbf{u}\sin\theta\end{bmatrix}\)</span>，因此<span class="math inline">\(\log(\mathbf{q})=\mathbf{u}\theta\)</span>，那么 <span class="math display">\[
\mathbf{q}^t=\exp(t\mathbf{u}\theta)=
\begin{bmatrix}
\cos t\theta\\
\mathbf{u}\sin t\theta
\end{bmatrix}
\]</span></p>
<h1 id="参考资料">参考资料</h1>
<p><a href="https://arxiv.org/pdf/1711.02508.pdf">Quaternion kinematics for the error-state Kalman filter</a></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>四元数</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机</title>
    <url>/2019/09/21/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="hard-margin">hard-margin</h1>
<h2 id="线性可分">线性可分</h2>
<p>假设数据点是线性可分的，即存在<span class="math inline">\((b,\mathbf{w})\)</span>满足 <span class="math display">\[
y_n(\mathbf{w}^T\mathbf{x}_n+b)&gt;0 \quad n=1,\dots,N
\]</span> <span class="math inline">\((b,\mathbf{w})\)</span>和<span class="math inline">\((\frac{b}{\rho},\frac{\mathbf{w}}{\rho})\)</span>表示同样的超平面。令 <span class="math display">\[
\rho = \min_{n=1,\dots,N}y_n(\mathbf{w}^T\mathbf{x}_n+b)
\]</span> 则对于同样的超平面<span class="math inline">\((b/\rho,\mathbf{w}/\rho)\)</span>，有 <span class="math display">\[
\min_{n=1,\dots,N}y_n\left(\frac{\mathbf{w}^T}{\rho}\mathbf{x}_n+\frac{b}{\rho}\right)=\frac{1}{\rho}\min_{n=1,\dots,N}y_n(\mathbf{w}^T\mathbf{x}_n+b)=\frac{\rho}{\rho}=1
\]</span> 因此可定义超平面<span class="math inline">\(h=(b,\mathbf{w})\)</span>满足 <span class="math display">\[
\min_{n=1,\dots,N}y_n(\mathbf{w}^T\mathbf{x}_n+b)=1
\]</span> 点<span class="math inline">\(\mathbf{x}\)</span>到<span class="math inline">\(h\)</span>的距离为 <span class="math display">\[
d(\mathbf{x},h)=\frac{|\mathbf{w}^T\mathbf{x}+b|}{\|\mathbf{w}\|}
\]</span> 由于<span class="math inline">\(y_n=\pm1\)</span>且线性可分 <span class="math display">\[
|\mathbf{w}^T\mathbf{x}+b|=|y_n(\mathbf{w}^T\mathbf{x}+b)|=y_n(\mathbf{w}^T\mathbf{x}+b)
\]</span> 那么 <span class="math display">\[
d(\mathbf{x}_n,h)=\frac{y_n(\mathbf{w}^T\mathbf{x}_n+b)}{\|\mathbf{w}\|}
\]</span> 所有点到超平面距离的最小值称为<strong>margin</strong>： <span class="math display">\[
\min_{n=1,\dots,N}d(\mathbf{x}_n,h)=\frac{1}{\|\mathbf{w}\|}\cdot\min_{n=1,\dots,N}y_n(\mathbf{w}^T\mathbf{x}_n+b)=\frac{1}{\|\mathbf{w}\|}
\]</span> 我们希望得到margin最大的超平面。让<span class="math inline">\(\frac{1}{\|\mathbf{w}\|}\)</span>最大也就是让<span class="math inline">\(\mathbf{w}^T\mathbf{w}\)</span>最小，因此问题归结于： <span class="math display">\[
\begin{aligned}
\min_{b,\mathbf{w}}&amp;\quad\frac{1}{2}\mathbf{w}^T\mathbf{w}\\
s.t.&amp;\quad\min_{n=1,\dots,N}y_n(\mathbf{w}^T\mathbf{x}_n+b)=1
\end{aligned}
\]</span> ### 求解</p>
<p>为了容易求解，可以把条件 <span class="math inline">\(\min_ny_n(\mathbf{w}^T\mathbf{x}_n+b)=1\)</span> 换成 <span class="math display">\[
y_n(\mathbf{w}^T\mathbf{x}_n+b)\ge1 \quad n=1,\dots,N
\]</span> 这个条件显然比原条件宽松，但是可以证明问题的最优解必然满足<span class="math inline">\(\min_ny_n(\mathbf{w}^T\mathbf{x}_n+b)=1\)</span>。</p>
<p>用反证法。数据中同时存在正类和负类时必有<span class="math inline">\(\mathbf{w}\neq \mathbf{0}\)</span>（否则<span class="math inline">\(b&gt;0\)</span>且<span class="math inline">\(-b&gt;0\)</span>，矛盾）。</p>
<p>假设<span class="math inline">\((b^*,\mathbf{w}^*)\)</span>是问题的最优解，满足 <span class="math display">\[
\rho^*=\min_ny_n(\mathbf{w}^T\mathbf{x}_n+b)&gt;1
\]</span> 考虑<span class="math inline">\((b,\mathbf{w})=\frac{1}{\rho^*}(b^*,\mathbf{w}^*)\)</span>。则<span class="math inline">\(\|\mathbf{w}\|=\frac{1}{\rho^*}\|\mathbf{w}^*\|&lt;\|\mathbf{w}^*\|\)</span>，与<span class="math inline">\((b^*,\mathbf{w}^*)\)</span>是最优解矛盾，得证。</p>
<p>那么问题变为 <span class="math display">\[
\begin{aligned}
\min_{b,\mathbf{w}}&amp;\quad\frac{1}{2}\mathbf{w}^T\mathbf{w}\\
s.t.&amp;\quad y_n(\mathbf{w}^T\mathbf{x}_n+b)\ge1\quad\text{for all } n
\end{aligned}
\label{problem1}\tag{1}
\]</span> 这就是<strong>svm的primal问题</strong>，是个二次规划的问题。</p>
<h4 id="二次规划">二次规划</h4>
<p>标准形式： <span class="math display">\[
\mathbf{u}^*\leftarrow \text{QP}(Q,\mathbf{p},A,\mathbf{c})\\
\begin{aligned}
\min_{\mathbf{u}}&amp;\quad \frac{1}{2}\mathbf{u}^TQ\mathbf{u}+\mathbf{p}^T\mathbf{u}\\
s.t.&amp;\quad \mathbf{a}_m^T\mathbf{u}\ge c_m \quad m=1,\dots,M
\end{aligned}
\]</span> <span class="math inline">\((\ref{problem1})\)</span>可以写成标准形式： <span class="math display">\[
\begin{aligned}
\text{目标函数:}&amp;\quad\mathbf{u}=\begin{bmatrix}
b\\
\mathbf{u}
\end{bmatrix};Q=\begin{bmatrix}
0 &amp; \mathbf{0}_d^T\\
\mathbf{0}_d &amp; I_d
\end{bmatrix};\mathbf{p}=\mathbf{0}_{d+1}\\
\text{约束:}&amp;\quad \mathbf{a}_n^T=y_n\begin{bmatrix}
1 &amp; \mathbf{x}_n^T
\end{bmatrix};c_n=1;M=N
\end{aligned}
\]</span> 其中<span class="math inline">\(d\)</span>为<span class="math inline">\(\mathbf{x}\)</span>的维度。</p>
<p><span class="math inline">\(A=\begin{bmatrix}\mathbf{a}_1^T\\\vdots\\\mathbf{a}_N^T\end{bmatrix}\)</span>与线性规划中的数据矩阵<span class="math inline">\(X\)</span>相似，只不过每行多乘了<span class="math inline">\(y_n\)</span>。</p>
<p>如果<span class="math inline">\(Q\)</span>是半正定的，二次规划是凸的。这里的<span class="math inline">\(Q\)</span>满足条件。</p>
<p>令问题的解为超平面<span class="math inline">\(g=(b^*,\mathbf{w}^*)\)</span>，满足<span class="math inline">\(d(\mathbf{x}_n,g)=\frac{1}{\|\mathbf{w}^*\|}\)</span>的数据点称为<strong>support vector</strong>(candidate)。把支持（或者叫支撑更合适）向量以外的数据点拿掉后，得到的最优分离超平面不会变。</p>
<p>hard margin的意思是超平面到两边margin的范围内没有数据点。</p>
<h2 id="dual">dual</h2>
<p>现在考虑svm的对偶问题，因为在后面使用特征变换时会用到。</p>
<p>定义Lagrange函数： <span class="math display">\[
L(b,\mathbf{w},\alpha)=\frac{1}{2}\mathbf{w}^T\mathbf{w}+\sum_{n=1}^N\alpha_n(1-y_n(\mathbf{w}^T\mathbf{x}_n+b))
\]</span> 那么原问题和以下问题等价， <span class="math display">\[
\min_{b,\mathbf{w}}\left(\max_{\text{all }\alpha_n\ge0}L(b,\mathbf{w},\alpha)\right)
\]</span> 因为如果<span class="math inline">\((b,\mathbf{w})\)</span>不满足条件<span class="math inline">\(y_n(\mathbf{w}^T\mathbf{x}_n+b)\ge1\)</span>，那么<span class="math inline">\(\max_{\alpha_n\ge0}\alpha_n(1-y_n(\mathbf{w}^T\mathbf{x}_n+b))\to\infty\)</span>。反之，如果<span class="math inline">\((b,\mathbf{w})\)</span>满足所有条件，<span class="math inline">\(\max_{\text{all }\alpha_n\ge0}\sum_{n=1}^N\alpha_n(1-y_n(\mathbf{w}^T\mathbf{x}_n+b))=0\)</span>，即<span class="math inline">\(\max_{\text{all }\alpha_n\ge0}L(b,\mathbf{w},\alpha)=\frac{1}{2}\mathbf{w}^T\mathbf{w}\)</span>。</p>
<p>对于任意满足要求的<span class="math inline">\(\alpha&#39;\)</span>，因为<span class="math inline">\(\max_{\text{all }\alpha_n\ge0}L(b,\mathbf{w},\alpha)\ge L(b,\mathbf{w},\alpha&#39;)\)</span>，所以 <span class="math display">\[
\min_{b,\mathbf{w}}\left(\max_{\text{all }\alpha_n\ge0}L(b,\mathbf{w},\alpha)\right)\ge\min_{b,\mathbf{w}}L(b,\mathbf{w},\alpha&#39;)
\]</span> 由于上式对于任意<span class="math inline">\(\alpha&#39;\)</span>都成立，自然应该大于等于其中的最大者，即： <span class="math display">\[
\min_{b,\mathbf{w}}\left(\max_{\text{all }\alpha_n\ge0}L(b,\mathbf{w},\alpha)\right)\ge\max_{\text{all }\alpha&#39;_n\ge0}\min_{b,\mathbf{w}}L(b,\mathbf{w},\alpha&#39;)
\]</span> 右边换用符号<span class="math inline">\(\alpha\)</span>，即 <span class="math display">\[
\min_{b,\mathbf{w}}\left(\max_{\text{all }\alpha_n\ge0}L(b,\mathbf{w},\alpha)\right)\ge\max_{\text{all }\alpha_n\ge0}\left(\min_{b,\mathbf{w}}L(b,\mathbf{w},\alpha)\right)
\]</span> 上式左边为<strong>primal</strong>，右边为<strong>Lagrange dual</strong>。<span class="math inline">\(\ge\)</span>表示weak duality。</p>
<p>对于二次规划，如果满足以下条件：</p>
<ul>
<li>primal是convex的</li>
<li>primal存在可行解</li>
<li>约束是线性的</li>
</ul>
<p>那么<span class="math inline">\(\ge\)</span>可用<span class="math inline">\(=\)</span>取代，称为<strong>strong duality</strong>。</p>
<p>存在<span class="math inline">\((b,\mathbf{w},\alpha)\)</span>，对于两边都是最优解。</p>
<p>求解dual内层： <span class="math display">\[
\frac{\partial L}{\partial b}=0\Rightarrow\sum y_n\alpha_n=0\\
\]</span> <span class="math display">\[
\frac{\partial L}{\partial \mathbf{w}}=\mathbf{0}\Rightarrow\mathbf{w}=\sum \alpha_ny_n\mathbf{x}_n
\label{condition1}\tag{2}
\]</span></p>
<p>代入之后，dual变为： <span class="math display">\[
\max_{\text{all }\alpha\ge0,\sum y_n\alpha_n=0,\mathbf{w}=\sum \alpha_ay_n\mathbf{x}_n}-\frac{1}{2}\left\|\sum_{n=1}^N\alpha_ny_n\mathbf{x}_n\right\|^2+\sum_{n=1}^N\alpha_n
\]</span> 从前面的推导中可见，最优解应满足的（必要）条件有：</p>
<ul>
<li>primal有可行解：<span class="math inline">\(y_n(\mathbf{w}^T\mathbf{x}_n+b)\ge1\)</span></li>
<li>对dual解的限制：<span class="math inline">\(\alpha_n\ge0\)</span></li>
<li>dual内层最优条件：<span class="math inline">\(\sum y_n\alpha_n=0,\mathbf{w}=\sum \alpha_ay_n\mathbf{x}_n\)</span></li>
<li>primal内层最优条件(complementary slackness)：<span class="math inline">\(\alpha_n\left(1-y_n(\mathbf{w}^T\mathbf{x}_n+b)\right)=0 \label{slackness}\tag{3}\)</span></li>
</ul>
<p>这些称为<strong>KKT条件</strong>，这里也是充分条件（<em>如何证明？</em>）</p>
<p>将上式最大转为求最小，并展开第一项，得： <span class="math display">\[
\begin{aligned}
\min_{\alpha}&amp;\quad\frac{1}{2}\sum_{n=1}^N\sum_{m=1}^N\alpha_n\alpha_my_ny_m\mathbf{x}_n^T\mathbf{x}_m-\sum_{n=1}^N\alpha_n\\
s.t.&amp;\quad\sum_{n=1}^Ny_n\alpha_n=0\\
&amp;\quad\alpha_n\ge0\quad n=1,\dots,N
\end{aligned}
\]</span> 这就是<strong>svm的dual问题</strong>。写成二次规划的标准形式： <span class="math display">\[
\begin{aligned}
\min_{\alpha}&amp;\quad\frac{1}{2}\alpha^TQ\alpha-\mathbf{1}_{N}^T\alpha\\
s.t.&amp;\quad A\alpha\ge\mathbf{0}_{N+2}
\end{aligned}
\]</span> 其中 <span class="math display">\[
Q_{n,m}=y_ny_m\mathbf{x}_n^T\mathbf{x}_m\\
A=\begin{bmatrix}
\mathbf{y}^T\\
-\mathbf{y}^T\\
I_{N\times N}
\end{bmatrix}
\]</span> <span class="math inline">\(A\)</span>的前两行是因为<span class="math inline">\(\mathbf{y}^T\alpha=0\)</span>等价于<span class="math inline">\(\mathbf{y}^T\alpha\ge0\)</span>且<span class="math inline">\(\mathbf{y}^T\alpha\le0\)</span>。</p>
<p>可以看到，<span class="math inline">\(Q=X_sX_s^T\)</span>，其中<span class="math inline">\(X_s\)</span>为带符号的数据矩阵： <span class="math display">\[
\begin{aligned}
X_s=\begin{bmatrix}
y_1\mathbf{x}_1^T\\
\vdots\\
y_N\mathbf{x}_N^T
\end{bmatrix}
\end{aligned}
\]</span></p>
<p>因此<span class="math inline">\(Q\)</span>为半正定矩阵，这个二次规划问题是凸的。</p>
<p>要注意<span class="math inline">\(Q\)</span>是<span class="math inline">\(N\times N\)</span>的矩阵，<span class="math inline">\(N\)</span>比较大时占用很大内存，SMO？</p>
<h3 id="恢复svm的解">恢复svm的解</h3>
<p>现已求得最优解<span class="math inline">\(\alpha^*\)</span>，<span class="math inline">\(\mathbf{w}^*\)</span>由<span class="math inline">\((\ref{condition1})\)</span>得出： <span class="math display">\[
\mathbf{w}^*=\sum \alpha_n^*y_n\mathbf{x}_n
\]</span> <span class="math inline">\(\mathbf{w}^*\)</span>是<span class="math inline">\(y_n\mathbf{x}_n\)</span>的线性组合，这和感知机的学习算法的结果相似，称为<span class="math inline">\(\mathbf{w}\)</span>由数据表征。</p>
<p>如果数据中同时有正类和负类，由前面说明过的<span class="math inline">\(\mathbf{w}^*\ne\mathbf{0}\)</span>可知至少存在一个值<span class="math inline">\(\alpha^*_s\ne0\)</span>。那么由<span class="math inline">\((\ref{slackness})\)</span>得： <span class="math display">\[
y_s(\mathbf{w}^{*T}\mathbf{x}_s+b^*)=1
\]</span> 可知<span class="math inline">\((\mathbf{x}_s,y_s)\)</span>属于support vector candidates。</p>
<p>求得： <span class="math display">\[
\begin{aligned}
b^*&amp;=y_s-\mathbf{w}^{*T}\mathbf{x}_s\\
&amp;=y_s-\sum_{n=1}^Ny_n\alpha_n^*\mathbf{x}_n^T\mathbf{x}_s
\end{aligned}
\]</span> 容易看到，<span class="math inline">\(\mathbf{w}^{*}\)</span>和<span class="math inline">\(b^*\)</span>可以只用<span class="math inline">\(\alpha_n^*&gt;0\)</span>对应的数据点得到，这些数据点称为support vector。</p>
<h2 id="kernel-trick">kernel trick</h2>
<p>如果在<span class="math inline">\(\mathbf{x}\)</span>空间中不是线性可分，考虑特征变换：<span class="math inline">\(\mathbf{z}=\Phi(\mathbf{x})\)</span>，看在<span class="math inline">\(\mathbf{z}\)</span>空间中能否做得更好。设<span class="math inline">\(\mathbf{x}\)</span>的维度为<span class="math inline">\(d\)</span>，<span class="math inline">\(\mathbf{z}\)</span>的维度为<span class="math inline">\(\tilde{d}\)</span>。计算<span class="math inline">\(Q_{n,m}=y_ny_m\mathbf{z}_n^T\mathbf{z}_m\)</span>复杂度为<span class="math inline">\(O(\tilde{d})\)</span>。需要降低计算<span class="math inline">\(\mathbf{z}_n^T\mathbf{z}_m=\Phi(\mathbf{x}_n)^T\Phi(\mathbf{x}_m)\)</span>的复杂度。</p>
<p>二阶多项式变换：<span class="math inline">\(\Phi_2(\mathbf{x})=(1,x_1,x_2,\dots,x_d,x_1x_1,x_1x_2,\dots,x_dx_d)\)</span>，这里为了后面推导方便，同时包含了<span class="math inline">\(x_ix_j\)</span>和<span class="math inline">\(x_jx_i\)</span>。 <span class="math display">\[
\begin{aligned}
\Phi_2(\mathbf{x})^T\Phi_2(\mathbf{x}&#39;)&amp;=1+\sum_{i=1}^dx_ix_i&#39;+\sum_{i=1}^d\sum_{j=1}^dx_ix_jx_i&#39;x_j&#39;\\
&amp;=1+\sum_{i=1}^dx_ix_i&#39;+\sum_{i=1}^dx_ix_i&#39;\sum_{j=1}^dx_jx_j&#39;\\
&amp;=1+\mathbf{x}^T\mathbf{x}&#39;+(\mathbf{x}^T\mathbf{x}&#39;)^2
\end{aligned}
\]</span> 只需要<span class="math inline">\(O(d)\)</span>的复杂度，而<span class="math inline">\(\tilde{d}=O(d^2)\)</span>。</p>
<p>kernel就是变换+内积。</p>
<p>kernel function：<span class="math inline">\(K_\Phi(\mathbf{x},\mathbf{x}&#39;)\triangleq \Phi(\mathbf{x})^T\Phi(\mathbf{x}&#39;)\)</span></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>感知机</title>
    <url>/2019/08/31/%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
    <content><![CDATA[<p>正类用+1表示，负类用-1表示，希望学得 <span class="math display">\[
f(\mathbf{x})=\text{sign}(\mathbf{w}\cdot\mathbf{x}+b)
\]</span> <span class="math inline">\(\mathbf{w}\cdot\mathbf{x}+b=0\)</span>是一个超平面，希望它能完全分隔正类/负类。这里假设这是可以做到的，称为线性可分。</p>
<h1 id="损失函数">损失函数</h1>
<p>任一点<span class="math inline">\(\mathbf{x}_0\)</span>到超平面的距离为： <span class="math display">\[
\frac{|\mathbf{w}\cdot\mathbf{x}_0+b|}{\|\mathbf{w}\|}
\]</span> 对于误分类的数据<span class="math inline">\((\mathbf{x}_i,y_i)\)</span>来说， <span class="math display">\[
-y_i(\mathbf{w}\cdot\mathbf{x}_i+b)&gt;0
\]</span> 因此，误分类点<span class="math inline">\(\mathbf{x}_i\)</span>到超平面的距离为 <span class="math display">\[
\frac{-y_i(\mathbf{w}\cdot\mathbf{x}_i+b)}{\|\mathbf{w}\|}
\]</span> 假设误分类点的集合为<span class="math inline">\(M\)</span>，那么总距离为 <span class="math display">\[
-\frac{1}{\|\mathbf{w}\|}\sum_{\mathbf{x}_i\in M}y_i(\mathbf{w}\cdot\mathbf{x}_i+b)
\]</span> 不考虑<span class="math inline">\(\frac{1}{\|\mathbf{w}\|}\)</span>，就得到损失函数： <span class="math display">\[
L(\mathbf{w},b)=-\sum_{\mathbf{x}_i\in M}y_i(\mathbf{w}\cdot\mathbf{x}_i+b)
\]</span> 令<span class="math inline">\(x_0=1,w_0=b\)</span>，可以写成： <span class="math display">\[
-\sum_{\mathbf{x}_i\in M}y_i\mathbf{w}\cdot\mathbf{x}_i
\]</span></p>
<h1 id="求解">求解</h1>
<p>接下来用随机梯度下降求解，即每次只选取一个误分类点使用梯度下降。假设选取的误分类点为<span class="math inline">\((\mathbf{x}_i,y_i)\)</span>， <span class="math display">\[
\mathbf{w}\leftarrow\mathbf{w}+\eta y_i\mathbf{x}_i
\]</span> 其中<span class="math inline">\(\eta\)</span>为步长（学习率）。</p>
<p>更新之后 <span class="math display">\[
\begin{aligned}
y_i(\mathbf{w}+\eta y_i\mathbf{x}_i)\cdot \mathbf{x}_i&amp;=y_i\mathbf{w}\cdot \mathbf{x}_i+\eta\mathbf{x}_i\cdot \mathbf{x}_i\\
&amp;\geq y_i\mathbf{w}\cdot \mathbf{x}_i
\end{aligned}
\]</span></p>
<p>所以更新后更接近正确分类（<span class="math inline">\(y_i\mathbf{w}\cdot \mathbf{x}_i&gt;0\)</span>）。</p>
<h1 id="算法收敛性">算法收敛性</h1>
<p>从上面的过程可以看出，在纠正一个误分类点时，可能会使原来正确分类的点被误分类。如何证明算法收敛？</p>
<p>因为线性可分，存在<span class="math inline">\(\|\mathbf{w}_f\|=1\)</span>，使得 <span class="math display">\[
\forall i\quad y_i\mathbf{w}_f\cdot\mathbf{x}_i\geq\min_n y_n\mathbf{w}_f\cdot\mathbf{x}_n\triangleq\gamma&gt;0
\]</span> <span class="math inline">\(\mathbf{w}_k\)</span>表示第<span class="math inline">\(k\)</span>轮更新后的参数，<span class="math inline">\(\mathbf{w}_0\)</span>设为全0向量。</p>
<p>假设<span class="math inline">\((\mathbf{x}_i,y_i)\)</span>是第<span class="math inline">\(k\)</span>轮更新中被选中的误分类点 <span class="math display">\[
\begin{aligned}
\mathbf{w}_f\cdot\mathbf{w}_{k}&amp;=\mathbf{w}_f\cdot(\mathbf{w}_{k-1}+\eta y_i\mathbf{x}_i)\\
&amp;\geq \mathbf{w}_f\cdot\mathbf{w}_{k-1}+\eta\gamma\\
&amp;\geq\dots\\
&amp;\geq k\eta\gamma
\end{aligned}
\]</span> 还要看<span class="math inline">\(\|\mathbf{w}_k\|\)</span>的增长速度， <span class="math display">\[
\begin{aligned}
\|\mathbf{w}_k\|^2&amp;=\|\mathbf{w}_{k-1}\|^2+2\eta y_i\mathbf{w}_{k-1}\cdot\mathbf{x}_{i}+\eta^2\|\mathbf{x}_i\|^2\\
&amp;\leq\|\mathbf{w}_{k-1}\|^2+\eta^2\|\mathbf{x}_i\|^2\quad(由误分类条件)\\
&amp;\leq\|\mathbf{w}_{k-1}\|^2+\eta^2R^2\quad(R^2\triangleq\max_i\|\mathbf{x}_i\|^2)\\
&amp;\leq\dots\\
&amp;\leq k\eta^2R^2
\end{aligned}
\]</span> 那么由 <span class="math display">\[
\frac{k\eta\gamma}{\sqrt{k}\eta R}\leq\mathbf{w}_f\cdot\frac{\mathbf{w}_k}{\|\mathbf{w}_k\|}\leq 1
\]</span> 得 <span class="math display">\[
k\leq \left(\frac{R}{\gamma}\right)^2
\]</span> 即迭代次数有上限，算法会收敛。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>最长上升子序列(LIS)的nlogn算法</title>
    <url>/2019/07/24/%E6%9C%80%E9%95%BF%E4%B8%8A%E5%8D%87%E5%AD%90%E5%BA%8F%E5%88%97(LIS)%E7%9A%84nlogn%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>序列用<span class="math inline">\(A\)</span>表示，处理到当前元素为止，长度为<span class="math inline">\(i\)</span>的子序列的最小的结尾元素用<span class="math inline">\(B_i\)</span>表示。序列<span class="math inline">\(B\)</span>是单调增的，即 <span class="math display">\[
i&lt;j\Leftrightarrow B_i&lt;B_j
\]</span> 因为如果<span class="math inline">\(B_i\geq B_j\)</span>，那么<span class="math inline">\(B_j\)</span>对应的子序列中的第<span class="math inline">\(i\)</span>个数是小于<span class="math inline">\(B_i\)</span>的，这与<span class="math inline">\(B_i\)</span>是最小的矛盾。 假设当前LIS长度为<span class="math inline">\(L\)</span>，现在要计算以<span class="math inline">\(A_k\)</span>结尾的LIS，只需二分长度<span class="math inline">\(l\)</span>，看是否满足<span class="math inline">\(B_l&lt;A_k\)</span>。假设以<span class="math inline">\(A_k\)</span>结尾的LIS长度为<span class="math inline">\(m\)</span>，再进行一次更新：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">B[m] &#x3D; min(B[m], A[k]);</span><br><span class="line">L &#x3D; max(L, m);</span><br></pre></td></tr></table></figure>
<p>即可。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title>算法时间复杂度渐进符号</title>
    <url>/2019/10/13/%E7%AE%97%E6%B3%95%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%B8%90%E8%BF%9B%E7%AC%A6%E5%8F%B7/</url>
    <content><![CDATA[<p>上界：</p>
<p><span class="math inline">\(T(n)=O(f(n))\)</span>当且仅当存在正的常数<span class="math inline">\(c,n_0\)</span>，使得： <span class="math display">\[
T(n)\le c\cdot f(n)\quad \forall n&gt;n_0
\]</span> 下界：</p>
<p><span class="math inline">\(T(n)=\Omega(f(n))\)</span>当且仅当存在正的常数<span class="math inline">\(c,n_0\)</span>，使得： <span class="math display">\[
T(n)\ge c\cdot f(n)\quad \forall n&gt;n_0
\]</span> 既是上界也是下界：</p>
<p><span class="math inline">\(T(n)=\Theta(f(n))\)</span>当且仅当存在正的常数<span class="math inline">\(c_1,c_2,n_0\)</span>，使得： <span class="math display">\[
c_1\cdot f(n)\le T(n)\le c_2\cdot f(n) \quad\forall n&gt;n_0
\]</span> <span class="math inline">\(T(n)=o(f(n))\)</span>当且仅当对于任意常数<span class="math inline">\(c&gt;0\)</span>，存在<span class="math inline">\(n_0\)</span>，使得： <span class="math display">\[
T(n)\le c\cdot f(n)\quad \forall n&gt;n_0
\]</span></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title>线性筛法</title>
    <url>/2019/08/10/%E7%BA%BF%E6%80%A7%E7%AD%9B%E6%B3%95/</url>
    <content><![CDATA[<p>线性筛法不仅是线性的（每个数只筛一次），还能得到每个数的最小素因子，而有了这，因式分解就很容易了。</p>
<p>对于合数<span class="math inline">\(x\)</span>，令<span class="math inline">\(p_x\)</span>表示<span class="math inline">\(x\)</span>的最小素因子，则 <span class="math display">\[
x=i*p_x
\]</span> 每个合数就是在<span class="math inline">\(i=x/p_x\)</span>的时候筛掉的，也就是尽可能晚的时候。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N=<span class="number">1e5</span>;</span><br><span class="line"><span class="keyword">int</span> minPrimeFactor[N+<span class="number">1</span>];</span><br><span class="line">vector&lt;<span class="keyword">int</span>&gt; primes;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">linearSieve</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">2</span>; i&lt;=N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (minPrimeFactor[i] == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            minPrimeFactor[i] = i;</span><br><span class="line">            primes.<span class="built_in">push_back</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> p : primes)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (p &gt; minPrimeFactor[i] || i * p &gt; N)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            minPrimeFactor[i*p] = p;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="参考资料">参考资料</h1>
<p><a href="https://www.hackerrank.com/topics/sieve-of-eratosthenes-linear-time">hackerrank</a></p>
<p>David Gries, Jayadev Misra. A Linear Sieve Algorithm for Finding Prime Numbers [1978]</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title>Biject Inside</title>
    <url>/2019/07/24/%E7%AE%97%E6%B3%95%E9%A2%98%E8%A7%A3/Biject%20Inside/</url>
    <content><![CDATA[<p><a href="https://www.hackerearth.com/zh/problem/algorithm/biject-outside-aa04dd45/description/">题目地址</a><br />
又是想了很久也没做出来，写下官方题解吧。</p>
<h1 id="题意">题意</h1>
<p>A随机选择1 ~ n的一个排列<span class="math inline">\(p\)</span>，B随机选择1 ~ n的一个子集<span class="math inline">\(S\)</span>，如果存在<span class="math inline">\(1\leq i \leq n\)</span>，使得<span class="math inline">\(i,p_i\)</span>都在<span class="math inline">\(S\)</span>中，A就赢了。问A赢的概率。</p>
<h1 id="题解">题解</h1>
<p>给定一个排列<span class="math inline">\(p\)</span>，要求有哪些集合使得A能赢是困难的，因为这和具体的排列有关。可以反过来，即给定<span class="math inline">\(B\)</span>的集合<span class="math inline">\(S\)</span>，求有多少种排列能让A赢，这个数只和<span class="math inline">\(|S|\)</span>有关，因此容易处理。<br />
下面先计算使A输的情况，因为这容易算。<br />
假设<span class="math inline">\(S\)</span>的大小为<span class="math inline">\(k\)</span>，令<span class="math inline">\(i=S_j\)</span>，其中<span class="math inline">\(1\leq j \leq k\)</span>。那么<span class="math inline">\(p_i\)</span>不能取<span class="math inline">\(S\)</span>中的元素，只能从剩下的<span class="math inline">\(n-k\)</span>个元素中选。这样的数量为<span class="math inline">\(A_{n-k}^k\)</span>。剩下的<span class="math inline">\(n-k\)</span>个<span class="math inline">\(i\)</span>对应的<span class="math inline">\(p_i\)</span>可以随便选，为<span class="math inline">\((n-k)!\)</span>，因此一个大小为<span class="math inline">\(k\)</span>的集合让A输的排列有<span class="math inline">\(A_{n-k}^k(n-k)!\)</span>种。再考虑到大小为<span class="math inline">\(k\)</span>的集合有<span class="math inline">\(C_{n}^k\)</span>个，最后对<span class="math inline">\(k\)</span>求和，总数为：<br />
<span class="math display">\[
\displaystyle\sum_{k=0}^n C_{n}^kA_{n-k}^k(n-k)!=n!\sum_{k=0}^nC_{n-k}^k  
\]</span> 需要计算<span class="math inline">\(\sum_{k=0}^nC_{n-k}^k\triangleq g_n\)</span>，这实际上和Fibonacci数<span class="math inline">\(F_n\)</span>有关。下面证明（<a href="https://math.stackexchange.com/questions/81805/how-to-show-that-this-binomial-sum-satisfies-the-fibonacci-relation">来源</a>）。<br />
考虑由0,1构成、没有1相邻的n位字符串的数量，记为<span class="math inline">\(f_{n}\)</span>。</p>
<h2 id="第一部分">第一部分</h2>
<p>建立<span class="math inline">\(g_n\)</span>和<span class="math inline">\(f_n\)</span>的联系。</p>
<p>计算有<span class="math inline">\(k\)</span>个1的串的数量：那么有<span class="math inline">\(n-k\)</span>个0，算上两端有<span class="math inline">\(n-k+1\)</span>个隔板，把<span class="math inline">\(k\)</span>个1放入隔板中，有<span class="math inline">\(C_{n-k+1}^k\)</span>种方法。枚举<span class="math inline">\(k\)</span>，总数为<span class="math inline">\(\sum_{k=0}^nC_{n-k+1}^k=g_{n+1}\)</span>。</p>
<p>因此<span class="math inline">\(g_{n}=f_{n-1}\)</span></p>
<h2 id="第二部分">第二部分</h2>
<p>证明<span class="math inline">\(f_{n}\)</span>是Fibonacci数。<br />
用<span class="math inline">\(f_{n,0}\)</span>表示串以0结尾的答案，<span class="math inline">\(f_{n,1}\)</span>表示以1结尾的答案。<br />
显然<br />
<span class="math display">\[
f_{n,0}=f_{n-1}\\  
f_{n,1}=f_{n-1,0}  
\]</span> 相加得：<br />
<span class="math inline">\(f_n=f_{n-1}+f_{n-1,0}=f_{n-1}+f_{n-2}\)</span><br />
而<span class="math inline">\(f_1=2,f_2=3\)</span><br />
如果按<a href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci数</a>的定义，就有<span class="math inline">\(f_n=F_{n+2}\)</span>。</p>
<p>由证明第一部分，得<span class="math inline">\(g_n=F_{n+1}\)</span></p>
]]></content>
      <categories>
        <category>算法题</category>
      </categories>
  </entry>
  <entry>
    <title>Superior Substring</title>
    <url>/2019/07/24/%E7%AE%97%E6%B3%95%E9%A2%98%E8%A7%A3/Superior%20Substring/</url>
    <content><![CDATA[<p><a href="https://www.hackerearth.com/zh/practice/algorithms/searching/binary-search/practice-problems/algorithm/superior-substring-dec-circuits-e51b3c27/">题目地址</a></p>
<h1 id="题意">题意</h1>
<p>核心问题是，给定一个长为<span class="math inline">\(N\)</span>的01串，连续子串中1的数量大于等于子串长度一半（向下取整）的为合法串。问合法串的最大长度。</p>
<h1 id="解法">解法</h1>
<p><span class="math inline">\(N\leq 10^5\)</span>，因此需要<span class="math inline">\(n\log n\)</span>的算法。<br />
我原以为这个长度会满足单调性，即如果长的串满足，短的一定满足。其实不对。比如<code>10001</code>，整个串满足条件，但找不到长度为4的合法串。<br />
下面给出官方题解。<br />
用<span class="math inline">\(f\)</span>表示累积和序列，那么对于<span class="math inline">\([L,R]\)</span>这个子串，原条件可表示为：<br />
<span class="math display">\[
f(R)-f(L-1)\geq \left\lfloor\frac{R-L+1}{2}\right\rfloor \quad(1)  
\]</span> 这个条件可以等价表示为<br />
<span class="math display">\[
f(R)-f(L-1)\geq \frac{R-L}{2} \quad(2)  
\]</span> <strong>证明</strong><br />
(1)-&gt;(2)<br />
因为<span class="math inline">\(\left\lfloor\frac{R-L+1}{2}\right\rfloor\geq \frac{R-L}{2}\)</span>（可根据<span class="math inline">\(R-L\)</span>的奇偶讨论）。<br />
(2)-&gt;(1)<br />
因为<span class="math inline">\(f(R)-f(L-1)\)</span>为整数，(2)实际上是<span class="math inline">\(f(R)-f(L-1)\geq \left\lceil\frac{R-L}{2}\right\rceil=\left\lfloor\frac{R-L+1}{2}\right\rfloor\)</span>。<br />
证毕。</p>
<p>(2)可变为 <span class="math display">\[
2f(R)-R\geq 2f(L-1)-L  
\]</span> 那么可形成两个这样的序列：<br />
<span class="math display">\[
p(i)=2f(i)-i\\  
q(i)=2f(i-1)-i  
\]</span> 为了得到以<span class="math inline">\(R\)</span>结尾的最长子串，就是要计算最小的满足<span class="math inline">\(p(R)\geq q(L)\)</span>的<span class="math inline">\(L\)</span>。<br />
当然这里要用二分来计算<span class="math inline">\(L\)</span>，否则就不能降低复杂度。然而<span class="math inline">\(q\)</span>并不是一个单调序列。<br />
实际上不需要完整的<span class="math inline">\(q\)</span>序列。如果<span class="math inline">\(q\)</span>中存在递增部分：<span class="math inline">\(i&lt;j\Rightarrow q(i)&lt;q(j)\)</span>，那么<span class="math inline">\(p(R)\geq q(j)\Rightarrow p(R)\geq q(i)\)</span>且<span class="math inline">\([i,R]\)</span>比<span class="math inline">\([j,R]\)</span>更长，因此不会选到<span class="math inline">\(j\)</span>。因此只要从<span class="math inline">\(i=1\)</span>开始，形成一个单调递减子序列<span class="math inline">\(q&#39;\)</span>，就可以做二分了。<br />
官方的程序用了一个比较聪明的做法，不是先提取单调子序列，而是改变元素值，使原序列成为（非严格）单调序列。方法是：如果下一个元素比现在的大，那么下一个元素变为与现在的一样大。</p>
]]></content>
      <categories>
        <category>算法题</category>
      </categories>
  </entry>
  <entry>
    <title>Yet Again a Subarray Problem</title>
    <url>/2019/07/24/%E7%AE%97%E6%B3%95%E9%A2%98%E8%A7%A3/Yet%20Again%20a%20Subarray%20Problem/</url>
    <content><![CDATA[<p><a href="https://www.codechef.com/problems/SUBPRNJL">题目</a></p>
<h1 id="题意">题意</h1>
<p>给定一个数组<span class="math inline">\(A\)</span>，长度<span class="math inline">\(N&lt;2000\)</span>，<span class="math inline">\(A_i&lt;2000\)</span>。对于它的每个连续子序列，计算这个子序列中第<span class="math inline">\(K\)</span>小的数（<span class="math inline">\(K\)</span>随子序列而不同，这不是问题重点），记为<span class="math inline">\(x\)</span>，得到<span class="math inline">\(x\)</span>在子序列中出现的次数<span class="math inline">\(F\)</span>。如果<span class="math inline">\(F\)</span>在子序列中也出现过，那么答案加一，求总的答案。</p>
<h1 id="题解">题解</h1>
<h2 id="解法一-线段树">解法一 线段树</h2>
<p>对于左端点下标为<span class="math inline">\(i\)</span>的子序列，在递增右端点的过程中，可以连续处理。线段树中节点保存的是值在<span class="math inline">\([l,r]\)</span>之间的数在当前子序列中出现的次数，而不是序列中的下标。那么根据左子节点中保存的数和<span class="math inline">\(K\)</span>的关系，很容易找到第<span class="math inline">\(K\)</span>小的数对应的叶节点，也就得到<span class="math inline">\(F\)</span>。然后再看<span class="math inline">\(F\)</span>对应的叶节点中保存的出现次数是否为0即可。</p>
<h2 id="解法二-预处理二分">解法二 预处理+二分</h2>
<p>首先预处理得到<code>PRE[x][r]</code>，表示<span class="math inline">\([1,r]\)</span>子序列中<span class="math inline">\(\leq x\)</span>的数的个数。预处理后可以<span class="math inline">\(O(1)\)</span>计算<span class="math inline">\([l,r]\)</span>子序列中<span class="math inline">\(\leq x\)</span>的数的个数。二分<span class="math inline">\(x\)</span>就可得到第<span class="math inline">\(K\)</span>小的数。根据<code>PRE[x][r]</code>也可以<span class="math inline">\(O(1)\)</span>得到<span class="math inline">\([l,r]\)</span>子序列中等于<span class="math inline">\(x\)</span>的数的个数，因此问题解决。</p>
]]></content>
      <categories>
        <category>算法题</category>
      </categories>
  </entry>
</search>
