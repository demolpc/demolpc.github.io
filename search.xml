<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[四元数]]></title>
    <url>%2F2019%2F08%2F17%2F%E5%9B%9B%E5%85%83%E6%95%B0%2F</url>
    <content type="text"><![CDATA[定义 \[ Q = a+bi+cj+dk \] 其中\({i,j,k}\)是虚数单元，满足： \[ i^2=j^2=k^2=ijk=-1 \] \(Q=a\)称为实四元数，\(Q=bi+cj+dk\)称为虚四元数。 实部+虚部的表示方式有时不方便，只要遵循虚部的运算规则，就可以写成标量+向量的形式： \[ Q=q_w+q_xi+q_yj+q_zk\quad \Leftrightarrow\quad Q=q_w+\mathbf{q}_v \] 下面将四元数\(Q\)写成四维向量\(\mathbf{q}\)的形式： \[ \mathbf{q}\triangleq \begin{bmatrix} q_w\\ \mathbf{q}_v \end{bmatrix}= \begin{bmatrix} q_w\\ q_x\\ q_y\\ q_z \end{bmatrix} \] 这样就可以用矩阵来进行有关四元数的运算。 主要性质 乘法 四元数的乘法只要按定义来进行就行了，用标量和向量的形式来表示是比较方便的： \[ \mathbf{p}\otimes\mathbf{q}= \begin{bmatrix} p_wq_w-\mathbf{p}_v^\top\mathbf{q}_v\\ p_w\mathbf{q}_v+q_w\mathbf{p}_v+\mathbf{p}_v\times\mathbf{q}_v \end{bmatrix} \] 由于结果的向量部分有个叉积，而叉积不满足交换律，因此四元数乘法一般也不满足交换律，即： \[ \mathbf{p}\otimes\mathbf{q}\neq\mathbf{q}\otimes\mathbf{p} \] 但是乘法满足结合律（暴力验证）： \[ (\mathbf{p}\otimes\mathbf{q})\otimes\mathbf{r}=\mathbf{p}\otimes(\mathbf{q}\otimes\mathbf{r}) \] 四元数乘法可以写成矩阵乘法的形式： \[ \mathbf{q_1}\otimes\mathbf{q_2}=[\mathbf{q_1}]_L\mathbf{q_2}\\ \mathbf{q_1}\otimes\mathbf{q_2}=[\mathbf{q_2}]_R\mathbf{q_1} \] 其中 \[ [\mathbf{q}]_L=q_w\mathbf{I}+ \begin{bmatrix} 0 &amp; -\mathbf{q}_v^\top\\ \mathbf{q}_v &amp; [\mathbf{q}_v]_{\times} \end{bmatrix} \] \[ [\mathbf{q}]_R=q_w\mathbf{I}+ \begin{bmatrix} 0 &amp; -\mathbf{q}_v^\top\\ \mathbf{q}_v &amp; -[\mathbf{q}_v]_{\times} \end{bmatrix} \] 这里用到了反对称矩阵： \[ [\mathbf{a}]_{\times}\triangleq \begin{bmatrix} 0 &amp; -a_z &amp; a_y\\ a_z &amp; 0 &amp; -a_x\\ -a_y &amp; a_x &amp; 0 \end{bmatrix} \] 这个矩阵和叉积有关： \[ [\mathbf{a}]_{\times}\mathbf{b}=\mathbf{a}\times\mathbf{b} \] 由于 \[ \begin{aligned} \mathbf{q}\otimes\mathbf{x}\otimes\mathbf{p}&amp;=(\mathbf{q}\otimes\mathbf{x})\otimes\mathbf{p}=[\mathbf{p}]_R[\mathbf{q}]_L\mathbf{x}\\ &amp;=\mathbf{q}\otimes(\mathbf{x}\otimes\mathbf{p})=[\mathbf{q}]_L[\mathbf{p}]_R\mathbf{x} \end{aligned} \] 可见L,R矩阵满足交换律： \[ [\mathbf{p}]_R[\mathbf{q}]_L=[\mathbf{q}]_L[\mathbf{p}]_R \] identity 单位四元数\(\mathbf{q_1}\)满足： \[ \mathbf{q_1}\otimes\mathbf{q}=\mathbf{q}\otimes\mathbf{q_1}=\mathbf{q} \] 它就是实数1： \[ \mathbf{q_1}=1= \begin{bmatrix} 1\\ \mathbf{0}_v \end{bmatrix} \] 共轭 和复数类似，共轭定义为： \[ \mathbf{q}^*\triangleq q_w-\mathbf{q}_v= \begin{bmatrix} q_w\\ -\mathbf{q}_v \end{bmatrix} \] 满足： \[ \mathbf{q}\otimes\mathbf{q}^*=\mathbf{q}^*\otimes\mathbf{q}=q_w^2+q_x^2+q_y^2+q_z^2 \] \[ (\mathbf{p}\otimes\mathbf{q})^*=\mathbf{q}^*\otimes\mathbf{p}^* \] norm 范数定义为： \[ \|\mathbf{q}\| \triangleq \sqrt{\mathbf{q}\otimes\mathbf{q}^*}=\sqrt{q_w^2+q_x^2+q_y^2+q_z^2} \] 满足： \[ \|\mathbf{p}\otimes\mathbf{q}\|=\|\mathbf{p}\|\|\mathbf{q}\| \] 逆 逆定义为： \[ \mathbf{q}\otimes\mathbf{q}^{-1}=\mathbf{q}^{-1}\otimes\mathbf{q}=\mathbf{q}_1 \] 显然， \[ \mathbf{q}^{-1}=\frac{\mathbf{q}^*}{\|\mathbf{q}\|^2} \] 单元四元数 或者叫归一化的四元数定义为\(\|\mathbf{q}\|=1\)，因此 \[ \mathbf{q}^{-1}=\mathbf{q}^* \] 单元四元数可以写成： \[ \mathbf{q}= \begin{bmatrix} \cos\theta\\ \mathbf{u}\sin\theta \end{bmatrix} \] 其中\(\mathbf{u}\)为单位向量。 附加性质 虚四元数的乘法 \[ \mathbf{q}_v\otimes\mathbf{q}_v=-\mathbf{q}_v^\top\mathbf{q}_v=-\|\mathbf{q}_v\|^2 \] 对于单位长度的虚四元数\(\|\mathbf{u}\|=1\)，因此： \[ \mathbf{u}\otimes \mathbf{u}=-1 \] 与虚数\(i\cdot i=-1\)类似。 虚四元数的指数函数 与实数类似，根据级数展开来定义： \[ e^{\mathbf{q}}\triangleq \sum_{0}^{\infty}\frac{1}{k!}\mathbf{q}^k \] 对于虚四元数\(\mathbf{v}=\mathbf{u}\theta\)，其中\(\mathbf{u}\)为单位长度，有： \[ e^{\mathbf{v}}=e^{\mathbf{u}\theta}=\cos\theta+\mathbf{u}\sin\theta= \begin{bmatrix} \cos\theta\\ \mathbf{u}\sin\theta \end{bmatrix} \] 是虚数的欧拉公式的扩展。 注意\(\|e^{\mathbf{v}}\|=1\)，因此虚四元数的指数函数为单元四元数。 一般四元数的指数函数 由于当其中一个四元数为实数时，四元数乘法满足交换律，因此： \[ e^{\mathbf{q}}=e^{q_w+\mathbf{q}_v}=e^{q_w}e^{\mathbf{q}_v} \] 单位四元数的对数 四元数的对数用指数来定义，如果\(\|\mathbf{q}\|=1\)， \[ \log \mathbf{q}=\log(\cos\theta+\mathbf{u}\sin\theta)=\log(e^{\mathbf{u}\theta})=\mathbf{u}\theta \] Exponential forms of the type \(\mathbf{q}^t\) 对于\(t\in \mathbb{R}\)， \[ \mathbf{q}^t=\exp(\log(\mathbf{q}^t))=\exp(t\log(\mathbf{q})) \] 如果\(\|\mathbf{q}\|=1\)，写成\(\mathbf{q}=\begin{bmatrix}\cos\theta, &amp; \mathbf{u}\sin\theta\end{bmatrix}\)，因此\(\log(\mathbf{q})=\mathbf{u}\theta\)，那么 \[ \mathbf{q}^t=\exp(t\mathbf{u}\theta)= \begin{bmatrix} \cos t\theta\\ \mathbf{u}\sin t\theta \end{bmatrix} \] 参考资料 Quaternion kinematics for the error-state Kalman filter]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>四元数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奇异值分解]]></title>
    <url>%2F2019%2F08%2F10%2F%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[对称矩阵的特征值分解： \[ A=VDV^T \] 特征向量\(\{v_i\}\)是正交归一的，作为空间的一组基很方便。 从线性变换的角度，\(A\)将\(\rm{R^n}\)中的向量\(x\)变换到同一个空间。对\(x\)做展开： \[ x = \sum_{i=1}^nc_iv_i \] 那么 \[ Ax = \sum_{i=1}^nc_i\delta_iv_i \] 即会根据特征值大小，对分量放大或缩小。 SVD 如果\(A\)是\(m\times n\)的矩阵，\(A\)将\(\rm{R^n}\)空间的向量\(x\)变换到\(\rm{R^m}\)，又该如何选择定义域和值域中的基呢？ \(\{v_1,v_2,\dots,v_n\}\)表示\(\rm{R^n}\)的一组正交归一基，其中\(\{v_1,v_2,\dots,v_k\}\)张成\(A\)的行空间（\(k\)为\(A\)的秩），那么 \[ Av_i\neq \mathbf{0} \quad 1\leq i\leq k \] \(\{Av_1,Av_2,\dots,Av_k\}\)也是线性无关的，因为如果存在不全为0的数\(c_i\)，使得 \[ \sum_{i=1}^kc_i(Av_i)=\sum_{i=1}^kA(c_iv_i)=\mathbf{0} \] 说明\(\sum_{i=1}^kc_iv_i\)在\(A\)的nullspace，这与\(v_i\)在行空间中矛盾。 \(\{u_1,u_2,\dots,u_m\}\)表示\(\rm{R^m}\)的一组归一化的基。将矩阵\(A\)表示为\(A=U\Sigma V^T\)（\(\Sigma\)为\(m\times n\)的矩阵，非零元只在主对角线上）并不难。只需让\(Av_i=\sigma_iu_i\)（\(v_i,u_i\)分别为\(V,U\)的第\(i\)列）。如上，虽然\(\{u_i=\frac{Av_i}{\sigma_i}, 1\leq i\leq k\}\)是线性无关的，但不能保证是正交的。 为了保证正交，我们不能任意选取\(\rm{R^n}\)的正交归一基作为\(V\)。 满足要求的\(\{v_i\}\)是\(A^TA\)的特征向量： \[ A^TAv_i=\lambda_iv_i \] 那么 \[ (Av_i)^T(Av_j)=v_i^TA^TAv_j=v_i^T(\lambda_jv_j)=\lambda_jv_i^Tv_j \] 因此\(Av_i\)与\(Av_j\)正交。 上式中令\(i=j\)，得 \[ \lambda_i=\|Av_i\|^2\geq 0 \] 排列特征值，使得： \[ \lambda_1\geq\lambda_2\geq\cdots\geq\lambda_k&gt;0\\ \lambda_{i}=0 \quad i&gt;k \] 由于\(i&gt;k\)时，\(\|Av_i\|=0\)，得到 \[ Av_i=\mathbf{0}\quad i&gt;k \] 因为\(\{v_i\}\)相互正交，所以\(k\)是\(A\)的秩。 为了得到\(\rm{R^m}\)中的一组基，归一化\(Av_i\)， \[ u_i=\frac{Av_i}{\|Av_i\|}=\frac{Av_i}{\sqrt{\lambda_i}}\quad 1\leq i\leq k \] 称\(\sigma_i=\sqrt{\lambda_i}\)为奇异值。 如果\(k&lt;m\)，继续补全基中还需的向量（按Gram–Schmidt过程来就行了）。]]></content>
      <categories>
        <category>数学</category>
        <category>线性代数</category>
      </categories>
      <tags>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实对称矩阵性质]]></title>
    <url>%2F2019%2F08%2F10%2F%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E6%80%A7%E8%B4%A8%2F</url>
    <content type="text"><![CDATA[特征值都是实数 证明： \[ \tag{1}Ax=\lambda x \] 两边左乘\(x\)的共轭转置： \[ \tag{2}\bar{x}^TAx=\lambda\bar{x}^Tx \] 对\((1)\)式取共轭，得： \[ \bar{A}\bar{x}=\bar{\lambda}\bar{x} \] 由于\(A\)是实矩阵，\(\bar{A}=A\)，因此： \[ A\bar{x}=\bar{\lambda}\bar{x} \] 两边取转置： \[ \begin{aligned} \bar{x}^TA^T&amp;=\bar{x}^TA\quad\text{$A$是对称阵}\\ &amp;=\bar{\lambda}\bar{x}^T \end{aligned} \] 右乘\(x\)，得： \[ \bar{x}^TAx=\bar{\lambda}\bar{x}^Tx \] 与\((2)\)式比较得： \[ \lambda\bar{x}^Tx=\bar{\lambda}\bar{x}^Tx \] 由于\(x\neq \mathbf{0}\)，那么\(\bar{x}^Tx=\sum\|x_i\|^2\neq 0\)，因此\(\lambda=\bar{\lambda}\)，即特征值为实数。 不同特征值对应的特征向量正交 证明： \[ \begin{aligned} x_2^TAx_1&amp;=x_2^T(Ax_1)\\ &amp;=\lambda_1x_2^Tx_1 \end{aligned} \] \[ \begin{aligned} x_2^TAx_1&amp;=(x_2^TA)x_1\\ &amp;=(A^Tx_2)^Tx_1\\ &amp;=(Ax_2)^Tx_1 \quad\text{$A$是对称阵}\\ &amp;=\lambda_2x_2^Tx_1 \end{aligned} \] 比较两式，得： \[ \lambda_1x_2^Tx_1=\lambda_2x_2^Tx_1 \] 因为\(\lambda_1\neq\lambda_2\)，因此\(x_2^Tx_1=0\) 对角化 由于不同特征值对应的特征向量正交，而同一个特征值如果有多重特征向量，可以用Gram–Schmidt正交化，因此一般的对角化\(A=PDP^{-1}\)中，可以通过选取合适的特征向量，使得\(P\)称为正交矩阵，因此可以对实对称阵正交对角化： \[ A=PDP^T \]]]></content>
      <categories>
        <category>数学</category>
        <category>线性代数</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hough变换]]></title>
    <url>%2F2019%2F08%2F10%2FHough%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[检测直线 给定二值图像中的\(n\)个点，要找到图像中的直线。一种方法是枚举所有可能的\(n*(n-1)/2\)条直线，然后检测每个点是否足够靠近线。如果足够靠近，就给这条线投一票。最后票数多的直线很可能是真正的直线。这样的复杂度是\(n^3\)的，对于一般的图片大小并不实用。 参数空间方法 Hough变换的思想最初是Hough在一篇专利中提出的。 考虑\(xy\)平面上的一点\((x_i,y_i)\)，假设通过这个点的某条直线的斜率为\(a\)，截距为\(b\)，那么\(y_i = ax_i+b\)。将式子写成\(b=-x_ia+y_i\)，即通过给定点的直线的斜率和截距满足一定关系。在\(ab\)平面（参数空间），这是一条直线。另一个点\((x_j,y_j)\)在参数空间也有一条关联的直线。如果这两条直线不平行，那么会交于一点\((a&#39;,b&#39;)\)。\((a&#39;,b&#39;)\)既是通过\((x_i,y_i)\)的某条直线的参数，又是通过\((x_j,y_j)\)的某条直线的参数，显然这条直线就是连接\((x_i,y_i)\)，\((x_j,y_j)\)的直线。 以上的方案有一点缺陷。我们知道只要\((x_i,y_i)\)，\((x_j,y_j)\)不是同一点，总能唯一确定一条直线。然而参数空间却有可能无法表示对应的参数值。也就是参数空间的两条直线平行的时候，无法求得参数。此时两条直线斜率相同：\(-x_i=-x_j\)。也就是当两点的\(x\)坐标相同时，连线是一条竖直的线，斜率无穷大，无法在参数空间表示。 法线表示 针对上述问题，我们现在用的Hough变换版本是Hart（和Duda）1972年在《Use of the Hough transformation to detect lines and curves in pictures》这篇论文中提出的。1 它利用的是直线的另一种表示：法线表示。 \[ x\cos\theta+y\sin\theta = \rho \] 其中\(\theta\)是直线的法线和\(x\)轴的夹角，\(\rho\)是原点到直线的距离（根据对\(\theta\)取值范围的规定，可能为负）。把上式写成向量\((x,y)\)与单位法向量\((\cos\theta,\sin\theta)\)的点积，就很显然。从几何上容易看出，\(\rho\)的最大取值为图像的对角线长度，因此不会有斜率-截距表示法中的无穷大问题。 图像中的一个点关联着\(\rho\theta\)参数空间中的一条正弦曲线。一条直线上的点对应的正弦曲线族在\(\rho\theta\)空间中会交于同一点。如果每个\((\theta,\rho)\)关联着一个累加器，其数值是参数空间中所有正弦曲线通过它的次数，那么某条直线对应的累积器数值就是直线上点的个数。我们无法枚举无限多的\((\theta,\rho)\)，Hough变换的做法是将\(\rho\theta\)空间按一定的分辨率网格化。对于图像中每个点，按设定的分辨率枚举所有的\(\theta\)，按\(\rho = x\cos\theta+y\sin\theta\) 得到对应的\(\rho\)，根据设定的\(\rho\)的分辨率得到对应网格，其累加器加一。最后把数值大的累加器对应的参数认定为直线。 opencv中的实现 opencv中\(\theta\)的取值范围为0到180度，那么\(\rho\)是有可能为负的。其范围为\(-D\leq\rho\leq D\)，其中\(D\)为对角线长。 实现在hough.cpp的HoughLinesStandard函数中。 123int max_rho = width + height;int min_rho = -max_rho;int numrho = cvRound(((max_rho - min_rho) + 1) / rho); 可以看到它取的\(\rho\)的最大值为宽加高，保证了大于对角线长。 123456789101112// stage 1. fill accumulatorfor( i = 0; i &lt; height; i++ ) for( j = 0; j &lt; width; j++ ) &#123; if( image[i * step + j] != 0 ) for(int n = 0; n &lt; numangle; n++ ) &#123; int r = cvRound( j * tabCos[n] + i * tabSin[n] ); r += (numrho - 1) / 2; accum[(n+1) * (numrho+2) + r+1]++; &#125; &#125; int r = cvRound( j * tabCos[n] + i * tabSin[n] );表示\(r = \frac{x\cos\theta+y\sin\theta}{\Delta\rho}\)，其中\(\Delta \rho\)为\(\rho\)的分辨率。这里\(r\)取值范围在\(-\frac{D}{\Delta \rho}\)和\(\frac{D}{\Delta \rho}\)之间，r += (numrho - 1) / 2;是为了把值shift到非负范围才能作为累加器的列索引。（累加器的行索引为\(\theta\)，列索引为\(\rho\)）。 下面的代码则是相应地还原回真正的\(\rho\)。 123int n = cvFloor(idx*scale) - 1;int r = idx - (n+1)*(numrho+2) - 1;line.rho = (r - (numrho - 1)*0.5f) * rho; 其他实现细节 在累加器矩阵中只会保留局部极大值，也就是比上下左右的累积器的值都要大才有可能输出，这样可以去掉非常接近的线。 结果是按累加器的值从大到小排序的。 指定\(\theta\)范围 在做跟踪的时候，可能只需要某个范围的\(\theta\)中做检测。Houghlines中可以指定最小和最大的\(\theta\)。如果是以两个点表示的直线，先要得到\(\theta\)值。由 \[ x_1\cos(\theta)+y_1\sin(\theta) = x_2\cos(\theta)+y_2\sin(\theta) = \rho \] 得： \[ \tan\theta = \frac{x_1-x_2}{y_2-y_1} \] 又因为在opencv中\(\theta\in [0,\pi]\)，因此 \[ \theta = \begin{cases} \arctan(\frac{x_1-x_2}{y_2-y_1}) , &amp; \text{if $\arctan(\frac{x_1-x_2}{y_2-y_1})\geq 0$ } \\ \pi - \arctan(\frac{x_1-x_2}{y_2-y_1}), &amp; \text{else} \end{cases} \] 直线和\(\theta\)对应关系如下图，可见在竖直线时\(\theta\)不连续变化。 有兴趣的可以看Hart写的《How the Hough transform was invented》了解这段历史↩︎]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Iterative Closest Point]]></title>
    <url>%2F2019%2F08%2F10%2FIterative%20Closest%20Point%2F</url>
    <content type="text"><![CDATA[问题 要把三维空间中的点集\(\{p_1,p_2,\cdots,p_n\}\)通过旋转、平移和点集\(\{q_1,q_2,\cdots,q_n\}\)匹配起来。\(p\)可能是预先给定的模型，而\(q\)是在另一个坐标系中观察的结果，匹配就是要找到两个坐标系的转换关系。 给定对应关系的情况 先考虑简单的情形，即给定了两个集合中点的对应关系，\(p_i\)对应\(q_i\)。 定义两个点集间的距离为： \[ \sum_{i=1}^n\|p_i-q_i\|^2 \] 我们的目标是找到旋转矩阵\(R\)、平移向量\(b\)，使得\(p\)变换后与\(q\)的距离最小 \[ \min_{R,b}\sum_{i=1}^n\|Rp_i+b-q_i\|^2 \] 目标函数对\(b\)求导并令导数为\(\mathbf{0}\)，得： \[ b=\bar{q}-R\bar{p} \] 其中 \[ \bar{p}=\frac{1}{n}\sum_{i=1}^np_i\\ \bar{q}=\frac{1}{n}\sum_{i=1}^nq_i\\ \] 分别是点集的“质心”。 将\(b\)的表达式代入目标函数，得到： \[ \sum_{i=1}^n\|Rp_i+b-q_i\|=\sum_{i=1}^n\|Rp_i&#39;-q_i&#39;\|^2 \] 其中： \[ p_i&#39;=p_i-\bar{p}\\ q_i&#39;=q_i-\bar{q} \] 为点相对于质心的坐标。 \[ \begin{aligned} \sum_{i=1}^n\|Rp_i&#39;-q_i&#39;\|^2&amp;=\sum_{i=1}^n(Rp_i&#39;\cdot Rp_i&#39;)-2\sum_{i=1}^n(Rp_i&#39;\cdot q_i&#39;)+\sum_{i=1}^n(q_i&#39;\cdot q_i&#39;)\\ &amp;=\sum_{i=1}^n(\|p_i&#39;\|^2+\|q_i&#39;\|^2)-2\sum_{i=1}^nRp_i&#39;\cdot q_i&#39; \end{aligned} \] 上式中\(Rp_i&#39;\cdot Rp_i&#39;=\|p_i&#39;\|^2\)是因为旋转不改变向量长度。 上式第一项与\(R\)无关，因此只要最小化第二项。或者等价地求如下最大化： \[ \max_R\sum_{i=1}^nRp_i&#39;\cdot q_i&#39; \] 下面用两种方法来求解。 采用新符号\(x_i=p_i&#39;\)，\(y_i=q_i&#39;\) SVD 用SVD推导时似乎常引用资料[4]，不过我下面采用资料[3]中的推导，因为更简单直接。 \[ \begin{aligned} \sum_{i=1}^nRx_i\cdot y_i&amp;=\sum_{i=1}^ny_i^TRx_i\\ &amp;=tr(\sum_{i=1}^ny_i^TRx_i) \quad\text{标量=标量的迹}\\ &amp;=tr(\sum_{i=1}^nx_iy_i^TR) \quad\text{因为tr(AB)=tr(BA)}\\ &amp;=tr(CR) \quad C\triangleq\sum_{i=1}^nx_iy_i^T\\ &amp;=tr(U\Lambda V^TR) \quad\text{SVD分解：$C=U\Lambda V^T$}\\ &amp;=tr(\Lambda V^TRU) \\ &amp;=tr(\Lambda T) \quad T\triangleq V^TRU\\ &amp;=\sum_{i=1}^3\lambda_iT_{ii} \end{aligned} \] 由于\(V,R,U\)都是正交矩阵，因此\(T\)是正交矩阵，即每一列的长度为1，则\(T_{ii}\leq 1\)，因此： \[ \sum_{i=1}^3\lambda_iT_{ii}\leq\sum_{i=1}^3\lambda_i \] 当\(T_{ii}=1\)时等号成立，此时\(T\)的其他元素为0，即\(T=I\)。由\(V^TRU=T=I\)，得旋转矩阵： \[ R=VU^T \] 当然旋转矩阵应该满足\(\det(R)=1\)。如果求得\(\det (VU^T)=-1\)，那说明\(T\)不能等于\(I\)。 \[ \begin{aligned} \det(T)&amp;=\det(V^TRU) \\ &amp;=\det(UV^TR) \\ &amp;=\det(UV^T)\det(R) \\ &amp;=-1 \end{aligned} \] 在这种情况下[3]中说 It is easy to see what the second largest value is 就是\(T_{11}=T_{22}=1,T_{33}=-1\)，不过我没有看出来为什么是这样。。 那相应的\(R\)变成 \[ R=V\begin{bmatrix} 1 &amp; &amp; \\ &amp; 1 &amp; \\ &amp; &amp; -1 \end{bmatrix}U^T \] [4]中说如果是有点集共面因而\(\lambda_3=0\)（因为此时\(C\)不是满秩），那么对结果没有影响。如果\(C\)满秩而反射（即\(\det(R)=-1\)）是最优解，那么很可能数据中有outlier。 四元数 用\(q\)来表示四元数。 由四元数表示旋转的方式得到下面的目标函数： \[ \sum_{i=1}^n(qx_iq^*)\cdot y_i \] 可以证明： \[ (qx_iq^*)\cdot y_i=(qx_i)\cdot(y_iq) \] 因此： \[ \begin{aligned} \sum_{i=1}^n(qx_iq^*)\cdot y_i &amp;=\sum_{i=1}^n(qx_i)\cdot(y_iq)\\ &amp;=\sum_{i=1}^n([x_i]_Rq)\cdot([y_i]_Lq)\\ &amp;=\sum_{i=1}^nq^T[x_i]_R^T[y_i]_Lq\\ &amp;=q^T\left(\sum_{i=1}^n[x_i]_R^T[y_i]_L\right)q\\ &amp;\triangleq q^TMq \end{aligned} \] 可以验证\([x_i]_R^T[y_i]_L\)是对称阵，因此\(M\)是对称阵。 那剩下的就是线代的标准内容了，\(q^TMq\)能取得的最大值为\(M\)的最大的特征值，对应的\(q\)为对应的归一化的特征向量。 ICP 接下来就是不知道对应点的情况，也就是ICP要解决的。 这部分比较简单。既然不知道\(p_i\)对应的\(q\)，那我可以把\(p_i\)与点集\(q\)中离它最近的点对应。假设这是在第\(k\)轮，这样得到的距离记为\(c_k\)（c代表correspondence）。 有了对应关系，就可以按上面的方法做配准，记得到的距离为\(d_k\)。因为我们做了最小化，显然 \[ d_k\leq c_k \] 对于变换后的点集\(p\)中的每个点，我们再在\(q\)中找距离最近的点。这样显然每个\(p_i\)对应的距离都只可能减小，因此总的距离也只会减小，即： \[ c_{k+1}\leq d_k \] 这样， \[ 0\leq d_{k+1} \leq c_{k+1} \leq d_k\leq c_k \] 单调下降有下界，因此会收敛到一个局部极小值。 实现时设定一个阈值\(\tau\)，当满足如下条件时停止迭代。 \[ d_k-d_{k+1}&lt;\tau \] 附录 四元数性质证明 只要证明： \[ (pq)\cdot r=p\cdot(rq^*) \] 然后代入 \[ p\leftarrow qx_i\\ q\leftarrow q^*\\ r\leftarrow y_i \] 就得证。 由于 \[ (pq)\cdot r = ([q]_Rp)^Tr=p^T[q]_R^Tr\\ p\cdot(rq^*)=p^T[q^*]_Rr \] 因此只要证： \[ [q]_R^T=[q^*]_R \] 而这是显然的。 对称阵验证 因为\(x\),\(y\)都是虚四元数， \[ \begin{aligned} \left[x\right]_R^\top[y]_L&amp;=\begin{bmatrix} 0 &amp; \mathbf{x}_v^\top\\ -\mathbf{x}_v &amp; [\mathbf{x}_v]_{\times} \end{bmatrix}\begin{bmatrix} 0 &amp; -\mathbf{y}_v^\top\\ \mathbf{y}_v &amp; [\mathbf{y}_v]_{\times} \end{bmatrix}\\ &amp;=\begin{bmatrix} \mathbf{x}_v^\top\mathbf{y}_v &amp; \mathbf{x}_v^\top[\mathbf{y}_v]_{\times}\\ [\mathbf{x}_v]_{\times}\mathbf{y}_v &amp; \mathbf{x}_v\mathbf{y}_v^\top+[\mathbf{x}_v]_{\times}[\mathbf{y}_v]_{\times} \end{bmatrix} \end{aligned} \] 其它都比较明显，只要证明 \[ \mathbf{x}_v\mathbf{y}_v^\top+[\mathbf{x}_v]_{\times}[\mathbf{y}_v]_{\times} \] 是对称阵。这个没想到好办法，直接验证了。 参考资料 四元数用于求解shape registration A Method for Registration of 3-D Shapes（ICP原始文献） SVD方法推导 Least-Squares Fitting of Two 3-D Point Sets （另一种SVD推导） Closed-form solution of absolute orientation using unit quaternions （四元数推导的原始文献）]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>ICP</tag>
        <tag>SVD</tag>
        <tag>四元数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EM算法]]></title>
    <url>%2F2019%2F07%2F24%2FEM%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[EM算法就是含有隐变量的概率模型参数的极大似然估计法（或极大后验概率估计法） 用\(x\)表示观测变量（的数据），\(z\)表示隐变量，\(\theta\)表示需要估计的模型参数。 给定观测数据\(x\)，其似然函数为\(p(x|\theta)\)，对数似然函数\(L(\theta) \triangleq \ln p(x|\theta)\)。 极大似然估计： \[ \max_{\theta}L(\theta) \] EM算法 算法是迭代进行的，假设第\(n\)轮迭代得到的参数估计为\(\theta_n\)，希望下一轮迭代使得\(L(\theta)&gt;L(\theta_n)\) \[ \begin{aligned} L(\theta)-L(\theta_n) &amp;=\ln \left(\sum_zp(z,x|\theta)\right)-\ln p(x|\theta_n)\\ \end{aligned} \] 对数函数是凹函数，满足Jensen不等式： \[ \log \left(\sum_j\lambda_jy_j\right)\geq \sum_j \lambda_j\log y_j \] 其中\(\lambda_j\geq 0, \sum_j\lambda_j=1\) 那么 \[ \begin{aligned} L(\theta)-L(\theta_n) &amp;=\ln \left(\sum_zp(z|x,\theta_n)\frac{p(z,x|\theta)}{p(z|x,\theta_n)}\right)-\ln p(x|\theta_n)\\ &amp;\geq \sum_zp(z|x,\theta_n)\ln\frac{p(z,x|\theta)}{p(z|x,\theta_n)}-\ln p(x|\theta_n)\\ &amp;=\sum_zp(z|x,\theta_n)\ln\frac{p(z,x|\theta)}{p(z|x,\theta_n)}-\left(\sum_zp(z|x,\theta_n)\right)\ln p(x|\theta_n)\\ &amp;=\sum_zp(z|x,\theta_n)\ln\frac{p(z,x|\theta)}{p(z,x|\theta_n)} \end{aligned} \] 即： \[ \begin{aligned} L(\theta)&amp;\geq L(\theta_n)+\sum_zp(z|x,\theta_n)\ln\frac{p(z,x|\theta)}{p(z,x|\theta_n)}\\ &amp;\triangleq B(\theta,\theta_n) \end{aligned} \] 也就是\(B(\theta,\theta_n)\)是\(L(\theta)\)的一个下界函数。而且容易看到： \[ B(\theta_n,\theta_n) = L(\theta_n) \] 即自变量等于\(\theta_n\)时，两个函数值是相等的。 那么如果找一个\(\theta_{n+1}\)，使得\(B(\theta_{n+1},\theta_n)\geq B(\theta_n,\theta_n)\)，就能使\(L(\theta)\)增大： \[ \begin{aligned} L(\theta_{n+1})&amp;\geq B(\theta_{n+1},\theta_n)\\ &amp;\geq B(\theta_n,\theta_n)\\ &amp;=L(\theta_n) \end{aligned} \] 一种方法是使： \[ \theta_{n+1}=\operatorname{argmax} B(\theta,\theta_n) \] 但是注意这样并不能保证\(L(\theta)\)的增长也能极大化，这和\(L(\theta)\)的具体形状有关。 使\(B(\theta,\theta_n)\)极大化，等价于极大化下面的式子，因为其他项为常数 \[ Q(\theta,\theta_n)\triangleq \sum_zp(z|x,\theta_n)\ln p(z,x|\theta) \] 这个式子有着鲜明的含义： 当有了\(x,\theta\)，根据\(z\)的概率分布\(p(z|x,\theta_n)\)可以采样出\(z\)，这样就有了完整的数据，可以做平常的极大似然估计。 因此EM算法的步骤是： E步：求完整数据对数似然的期望，这个期望是在概率分布\(p(z|x,\theta_n)\)下求的。 M步：极大化，只是保证\(L(\theta)\)增大的一种方式。 在E步中，\(\ln p(x,z|\theta)\)应该是很好算的，\(p(z|x,\theta)\)也好算： \[ p(z|x,\theta)=\frac{p(z,x|\theta)}{p(x|\theta)}=\frac{p(z,x|\theta)}{\sum_{z&#39;}p(z&#39;,x|\theta)} \]]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Yet Again a Subarray Problem]]></title>
    <url>%2F2019%2F07%2F24%2FYet%20Again%20a%20Subarray%20Problem%2F</url>
    <content type="text"><![CDATA[题目 题意 给定一个数组\(A\)，长度\(N&lt;2000\)，\(A_i&lt;2000\)。对于它的每个连续子序列，计算这个子序列中第\(K\)小的数（\(K\)随子序列而不同，这不是问题重点），记为\(x\)，得到\(x\)在子序列中出现的次数\(F\)。如果\(F\)在子序列中也出现过，那么答案加一，求总的答案。 题解 解法一 线段树 对于左端点下标为\(i\)的子序列，在递增右端点的过程中，可以连续处理。线段树中节点保存的是值在\([l,r]\)之间的数在当前子序列中出现的次数，而不是序列中的下标。那么根据左子节点中保存的数和\(K\)的关系，很容易找到第\(K\)小的数对应的叶节点，也就得到\(F\)。然后再看\(F\)对应的叶节点中保存的出现次数是否为0即可。 解法二 预处理+二分 首先预处理得到PRE[x][r]，表示\([1,r]\)子序列中\(\leq x\)的数的个数。预处理后可以\(O(1)\)计算\([l,r]\)子序列中\(\leq x\)的数的个数。二分\(x\)就可得到第\(K\)小的数。根据PRE[x][r]也可以\(O(1)\)得到\([l,r]\)子序列中等于\(x\)的数的个数，因此问题解决。]]></content>
      <categories>
        <category>算法题</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[最长上升子序列(LIS)的nlogn算法]]></title>
    <url>%2F2019%2F07%2F24%2F%E6%9C%80%E9%95%BF%E4%B8%8A%E5%8D%87%E5%AD%90%E5%BA%8F%E5%88%97(LIS)%E7%9A%84nlogn%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[序列用\(A\)表示，处理到当前元素为止，长度为\(i\)的子序列的最小的结尾元素用\(B_i\)表示。序列\(B\)是单调增的，即 \[ i&lt;j\Leftrightarrow B_i&lt;B_j \] 因为如果\(B_i\geq B_j\)，那么\(B_j\)对应的子序列中的第\(i\)个数是小于\(B_i\)的，这与\(B_i\)是最小的矛盾。 假设当前LIS长度为\(L\)，现在要计算以\(A_k\)结尾的LIS，只需二分长度\(l\)，看是否满足\(B_l&lt;A_k\)。假设以\(A_k\)结尾的LIS长度为\(m\)，再进行一次更新： 12B[m] = min(B[m], A[k]);L = max(L, m); 即可。]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Biject Inside]]></title>
    <url>%2F2019%2F07%2F24%2FBiject%20Inside%2F</url>
    <content type="text"><![CDATA[题目地址 又是想了很久也没做出来，写下官方题解吧。 题意 A随机选择1 ~ n的一个排列\(p\)，B随机选择1 ~ n的一个子集\(S\)，如果存在\(1\leq i \leq n\)，使得\(i,p_i\)都在\(S\)中，A就赢了。问A赢的概率。 题解 给定一个排列\(p\)，要求有哪些集合使得A能赢是困难的，因为这和具体的排列有关。可以反过来，即给定\(B\)的集合\(S\)，求有多少种排列能让A赢，这个数只和\(|S|\)有关，因此容易处理。 下面先计算使A输的情况，因为这容易算。 假设\(S\)的大小为\(k\)，令\(i=S_j\)，其中\(1\leq j \leq k\)。那么\(p_i\)不能取\(S\)中的元素，只能从剩下的\(n-k\)个元素中选。这样的数量为\(A_{n-k}^k\)。剩下的\(n-k\)个\(i\)对应的\(p_i\)可以随便选，为\((n-k)!\)，因此一个大小为\(k\)的集合让A输的排列有\(A_{n-k}^k(n-k)!\)种。再考虑到大小为\(k\)的集合有\(C_{n}^k\)个，最后对\(k\)求和，总数为： \[ \displaystyle\sum_{k=0}^n C_{n}^kA_{n-k}^k(n-k)!=n!\sum_{k=0}^nC_{n-k}^k \] 需要计算\(\sum_{k=0}^nC_{n-k}^k\triangleq g_n\)，这实际上和Fibonacci数\(F_n\)有关。下面证明（来源）。 考虑由0,1构成、没有1相邻的n位字符串的数量，记为\(f_{n}\)。 第一部分 建立\(g_n\)和\(f_n\)的联系。 计算有\(k\)个1的串的数量：那么有\(n-k\)个0，算上两端有\(n-k+1\)个隔板，把\(k\)个1放入隔板中，有\(C_{n-k+1}^k\)种方法。枚举\(k\)，总数为\(\sum_{k=0}^nC_{n-k+1}^k=g_{n+1}\)。 因此\(g_{n}=f_{n-1}\) 第二部分 证明\(f_{n}\)是Fibonacci数。 用\(f_{n,0}\)表示串以0结尾的答案，\(f_{n,1}\)表示以1结尾的答案。 显然 \[ f_{n,0}=f_{n-1}\\ f_{n,1}=f_{n-1,0} \] 相加得： \(f_n=f_{n-1}+f_{n-1,0}=f_{n-1}+f_{n-2}\) 而\(f_1=2,f_2=3\) 如果按Fibonacci数的定义，就有\(f_n=F_{n+2}\)。 由证明第一部分，得\(g_n=F_{n+1}\)]]></content>
      <categories>
        <category>算法题</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Superior Substring]]></title>
    <url>%2F2019%2F07%2F24%2FSuperior%20Substring%2F</url>
    <content type="text"><![CDATA[题目地址 题意 核心问题是，给定一个长为\(N\)的01串，连续子串中1的数量大于等于子串长度一半（向下取整）的为合法串。问合法串的最大长度。 解法 \(N\leq 10^5\)，因此需要\(n\log n\)的算法。 我原以为这个长度会满足单调性，即如果长的串满足，短的一定满足。其实不对。比如10001，整个串满足条件，但找不到长度为4的合法串。 下面给出官方题解。 用\(f\)表示累积和序列，那么对于\([L,R]\)这个子串，原条件可表示为： \[ f(R)-f(L-1)\geq \left\lfloor\frac{R-L+1}{2}\right\rfloor \quad(1) \] 这个条件可以等价表示为 \[ f(R)-f(L-1)\geq \frac{R-L}{2} \quad(2) \] 证明 (1)-&gt;(2) 因为\(\left\lfloor\frac{R-L+1}{2}\right\rfloor\geq \frac{R-L}{2}\)（可根据\(R-L\)的奇偶讨论）。 (2)-&gt;(1) 因为\(f(R)-f(L-1)\)为整数，(2)实际上是\(f(R)-f(L-1)\geq \left\lceil\frac{R-L}{2}\right\rceil=\left\lfloor\frac{R-L+1}{2}\right\rfloor\)。 证毕。 (2)可变为 \[ 2f(R)-R\geq 2f(L-1)-L \] 那么可形成两个这样的序列： \[ p(i)=2f(i)-i\\ q(i)=2f(i-1)-i \] 为了得到以\(R\)结尾的最长子串，就是要计算最小的满足\(p(R)\geq q(L)\)的\(L\)。 当然这里要用二分来计算\(L\)，否则就不能降低复杂度。然而\(q\)并不是一个单调序列。 实际上不需要完整的\(q\)序列。如果\(q\)中存在递增部分：\(i&lt;j\Rightarrow q(i)&lt;q(j)\)，那么\(p(R)\geq q(j)\Rightarrow p(R)\geq q(i)\)且\([i,R]\)比\([j,R]\)更长，因此不会选到\(j\)。因此只要从\(i=1\)开始，形成一个单调递减子序列\(q&#39;\)，就可以做二分了。 官方的程序用了一个比较聪明的做法，不是先提取单调子序列，而是改变元素值，使原序列成为（非严格）单调序列。方法是：如果下一个元素比现在的大，那么下一个元素变为与现在的一样大。]]></content>
      <categories>
        <category>算法题</category>
      </categories>
  </entry>
</search>
